{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esper tutorial\n",
    "\n",
    "This will walk you through a few of the APIs for accessing, visualizing, and processing data in the Esper environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Esper-tutorial\" data-toc-modified-id=\"Esper-tutorial-1\">Esper tutorial</a></span><ul class=\"toc-item\"><li><span><a href=\"#Django-ORM-examples\" data-toc-modified-id=\"Django-ORM-examples-1.1\">Django ORM examples</a></span></li><li><span><a href=\"#Visualizing-video\" data-toc-modified-id=\"Visualizing-video-1.2\">Visualizing video</a></span></li><li><span><a href=\"#Querying-captions\" data-toc-modified-id=\"Querying-captions-1.3\">Querying captions</a></span></li><li><span><a href=\"#Extracting-audiovisual-data\" data-toc-modified-id=\"Extracting-audiovisual-data-1.4\">Extracting audiovisual data</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import esper.prelude\n",
    "from query.models import Video, Face\n",
    "from esper.widget import esper_widget, qs_to_result, simple_result\n",
    "from esper.captions import phrase_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Django ORM examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Django to structure the code base, and we use its ORM to structure the data base. For example, we have a Video table that you can query using their ORM interface. In our dataset, each video is a 1-3 hour segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video.objects.all()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face bounding boxes are stored in the Face table. To see more tables, look at `app/query/models.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Face.objects.all()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Django ORM converts Python-ish queries into SQL, e.g. here counting # of faces on CNN\n",
    "(warning: this will take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Face.objects.filter(frame__video__channel__name='CNN').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing video\n",
    "To visualize results, we have a Jupyter-embedded widget that takes a data structure describing\n",
    "a visualization. Here, we have the qs_to_result helper function that converts a Django QuerySet\n",
    "into such a \"reuslt\" structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_to_result(Face.objects.all(), limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this structure with the esper_widget function.\n",
    "Note that we use a number of keybindings to interact with the Esper widget. If you go to the \n",
    "main page at http://35.185.221.100, you can see extended help. You will have to click the\n",
    "\"disable jupyter keyboard\" button while using the widget, since otherwise the keys conflict\n",
    "with Jupyter's (sadly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget = esper_widget(qs_to_result(Face.objects.all()))\n",
    "widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you select clips in the widget by clicking \"s\" on the clip, then the indices of the selected clips\n",
    "are available in Python here. This is useful for doing labeling tasks inside a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget.selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying captions\n",
    "We have Python libraries for searching through our captions. This one returns all instances of a particular\n",
    "phrase in the captions. The source files are located at `app/data/subs/orig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = phrase_search('MERRY CHRISTMAS')\n",
    "phrase_instance = next(generator)\n",
    "phrase_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the video clip corresponding to the phrase. Press \"p\" to play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esper_widget(simple_result([{\n",
    "    'video': phrase_instance.id,\n",
    "    'min_time': phrase_instance.postings[0].start,\n",
    "    'max_time': phrase_instance.postings[0].end\n",
    "}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting audiovisual data\n",
    "The video files are too big to be stored on any machine (unlike the captions). They're on Google Cloud Storage, at `gs://esper/tvnews/videos`. However, we have a number of APIs for accessing raw data. For example, we use the [`scannertools`](https://github.com/scanner-research/scannertools) API to access individual frames of a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "video = Video.objects.all()[0]\n",
    "plt.imshow(video.for_scannertools().frame(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use ffmpeg to download segments of video or audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video.download(ext='aac', segment=(0, 10)))  # audio from time 0s to 10s\n",
    "print(video.download(ext='mp4', segment=(10, 20))) # video+audio from time 10s to 20s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
