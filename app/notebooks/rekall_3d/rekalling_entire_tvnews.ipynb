{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T20:18:47.491806Z",
     "start_time": "2019-03-14T20:18:47.355225Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.prelude import *\n",
    "\n",
    "def get_fps_map(vids):\n",
    "    from query.models import Video\n",
    "    vs = Video.objects.filter(id__in=vids)\n",
    "    return {v.id: v.fps for v in vs}\n",
    "\n",
    "def frame_second_conversion(c, mode='f2s'):\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    from rekall.interval_set_3d import Interval3D\n",
    "    fps_map = get_fps_map(set(c.get_grouped_intervals().keys()))\n",
    "    \n",
    "    def second_to_frame(fps):\n",
    "        def map_fn(intrvl):\n",
    "            i2 = intrvl.copy()\n",
    "            t1,t2 = intrvl.t\n",
    "            i2.t = (int(t1*fps), int(t2*fps))\n",
    "            return i2\n",
    "        return map_fn\n",
    "    \n",
    "    def frame_to_second(fps):\n",
    "        def map_fn(intrvl):\n",
    "            i2 = intrvl.copy()\n",
    "            t1,t2 = intrvl.t\n",
    "            i2.t = (int(t1/fps), int(t2/fps))\n",
    "            return i2\n",
    "        return map_fn\n",
    "    \n",
    "    if mode=='f2s':\n",
    "        fn = frame_to_second\n",
    "    if mode=='s2f':\n",
    "        fn = second_to_frame\n",
    "    output = {}\n",
    "    for vid, intervals in c.get_grouped_intervals().items():\n",
    "        output[vid] = intervals.map(fn(fps_map[vid]))\n",
    "    return DomainIntervalCollection(output)\n",
    "\n",
    "def frame_to_second_collection(c):\n",
    "    return frame_second_conversion(c, 'f2s')\n",
    "\n",
    "def second_to_frame_collection(c):\n",
    "    return frame_second_conversion(c, 's2f')\n",
    "\n",
    "def convert_to_1d_collection(collection):\n",
    "    from rekall.interval_list import Interval\n",
    "    from rekall.video_interval_collection import VideoIntervalCollection\n",
    "    video_map = collection.get_grouped_intervals()\n",
    "    return VideoIntervalCollection({vid: [Interval(\n",
    "        i.t[0], i.t[1], None) for i in video_map[vid].get_intervals()] for vid in video_map})\n",
    "\n",
    "def display_result(collection_1d):\n",
    "    from esper.rekall import intrvllists_to_result\n",
    "    results = intrvllists_to_result(collection_1d.get_allintervals())\n",
    "    return esper_widget(results,\n",
    "            crop_bboxes=False, show_middle_frame=False, disable_captions=False,\n",
    "            results_per_page=25, jupyter_keybindings=True)  \n",
    "\n",
    "def topN(gen,n=25):\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    from rekall.runtime import disjoint_domain_combiner\n",
    "    result = None\n",
    "    count = 0\n",
    "    with tqdm(total=n) as pbar:\n",
    "        for collection in gen:\n",
    "            delta = len(collection.get_grouped_intervals())\n",
    "            pbar.update(delta)\n",
    "            count += delta\n",
    "            if result is None:\n",
    "                result = collection\n",
    "            else:\n",
    "                result = disjoint_domain_combiner(result, collection)\n",
    "            if count >= n:\n",
    "                break\n",
    "    return result\n",
    "\n",
    "# time dimension in seconds\n",
    "def get_commercial_intervals_in_vids(vids, in_seconds=True):\n",
    "    from query.models import Commercial\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    \n",
    "    qs = Commercial.objects.filter(video_id__in=vids)\n",
    "    commercials = DomainIntervalCollection.from_django_qs(qs)\n",
    "    if in_seconds:\n",
    "        return frame_to_second_collection(commercials)\n",
    "    return commercials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T20:18:54.590302Z",
     "start_time": "2019-03-14T20:18:48.469999Z"
    }
   },
   "outputs": [],
   "source": [
    "GUEST_LIST = [name.lower() for name in ['Barack Obama', 'Donald Trump', 'Ted Cruz', 'John Kasich', 'Marco Rubio', 'Ben Carson', 'Jeb Bush',\n",
    "'Jim Gilmore', 'Chris Christie', 'Carly Fiorina', 'Rick Santorum', 'Rand Paul', 'Mike Huckabee',\n",
    "'Hillary Clinton', 'Bernie Sanders', 'Lincoln Chafee', 'Martin Oâ€™Malley', 'Jim Webb',\n",
    "'Sarah Palin', 'John Boehner', 'Paul Ryan', 'Newt Gingrich','Nancy Pelosi','Elizabeth Warren', 'Mitch McConnell',\n",
    "'Chuck Schumer','Harry Reid','Joe Biden', 'Kevin McCarthy', 'Steve Scalise', 'Bobby Jindal', 'John Cornyn',\n",
    "'Dick Durbin','Orrin Hatch', 'Lindsey Graham', 'Mitt Romney', 'Michelle Obama' ,'Bill Clinton', \n",
    "'George W Bush', 'Tim Kaine' ]]\n",
    "HOST_LIST = list(set([h.name for s in CanonicalShow.objects.exclude(hosts=None) for h in s.hosts.all()]))\n",
    "VIDEOS = sorted([v.id for v in Video.objects.exclude(show__hosts=None)])\n",
    "\n",
    "def get_name_to_labeler_id(names):\n",
    "    from tqdm import tqdm\n",
    "    def get_labeler_ids(n):\n",
    "        from query.models import Labeler\n",
    "        labeler_names = ['face-identity:'+n, 'face-identity-converted:'+n, 'face-identity-uncommon:'+n]\n",
    "        return [l.id for l in Labeler.objects.filter(name__in=labeler_names)]\n",
    "    output = {}\n",
    "    for n in tqdm(names):\n",
    "        output[n] = get_labeler_ids(n)\n",
    "    return output\n",
    "\n",
    "NAME_TO_LABELER_ID = get_name_to_labeler_id(GUEST_LIST+HOST_LIST)\n",
    "\n",
    "def name_to_id(name):\n",
    "    from query.models import Identity\n",
    "    return Identity.objects.get(name=name).id\n",
    "\n",
    "GUEST_IDS=[name_to_id(n) for n in GUEST_LIST]\n",
    "HOST_IDS=[name_to_id(n) for n in HOST_LIST]\n",
    "\n",
    "# time dimension in seconds\n",
    "# Outputs a dictionary from name to video interval collection\n",
    "def get_person_intervals_in_vids(person_names, vids, probability=0.7, min_height=None):\n",
    "    from query.models import FaceIdentity\n",
    "    from django.db.models import F,Q\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    from rekall.interval_set_3d import Interval3D\n",
    "    from rekall.interval_set_3d_utils import P\n",
    "    \n",
    "    SAMPLE_RATE = 3 # Every 3s\n",
    "\n",
    "    lids = []\n",
    "    for n in person_names:\n",
    "        lids.extend(NAME_TO_LABELER_ID[n])\n",
    "    \n",
    "    face_id_qs = FaceIdentity.objects.filter(\n",
    "        probability__gte=probability,\n",
    "        face__frame__video_id__in=vids,\n",
    "        face__frame__shot_boundary=False,\n",
    "        labeler_id__in=lids,\n",
    "    ).annotate(\n",
    "        height=F('face__bbox_y2')-F('face__bbox_y1'),\n",
    "        labeler_name=F('labeler__name'),\n",
    "        video_id=F('face__frame__video_id'),\n",
    "        frame_number=F('face__frame__number'),\n",
    "        x1=F('face__bbox_x1'),\n",
    "        x2=F('face__bbox_x2'),\n",
    "        y1=F('face__bbox_y1'),\n",
    "        y2=F('face__bbox_y2'),\n",
    "    )\n",
    "    if min_height is not None:\n",
    "        face_id_qs = face_id_qs.filter(height__gte=min_height)\n",
    "    \n",
    "    faces = DomainIntervalCollection.from_django_qs(face_id_qs, {\n",
    "        't1':'frame_number',\n",
    "        't2':'frame_number',\n",
    "        'x1':'x1','x2':'x2','y1':'y1','y2':'y2',\n",
    "    }, with_payload=lambda row: row.labeler_name.split(':')[1], progress=False)\n",
    "\n",
    "    fps_map = get_fps_map(set(faces.get_grouped_intervals().keys()))\n",
    "    names_to_collection = {}\n",
    "    for n in person_names:\n",
    "        faces_one_person = faces.filter(P(lambda p: p==n))\n",
    "        output = {}\n",
    "        for vid, intervals in faces_one_person.get_grouped_intervals().items():\n",
    "            fps = fps_map[vid]\n",
    "            eps = round(fps * SAMPLE_RATE)\n",
    "            output[vid] = intervals.temporal_coalesce(epsilon=eps)\n",
    "        names_to_collection[n] = frame_to_second_collection(DomainIntervalCollection(output))\n",
    "    return names_to_collection\n",
    "\n",
    "# Returns interview_IS<person_only_IS<>, host_only_IS<>, person_with_host_IS<>>\n",
    "def interview_query(guest, hosts, commercials):\n",
    "    from rekall.interval_set_3d import Interval3D\n",
    "    from rekall.interval_set_3d_utils import T, P, or_preds, overlap_bound\n",
    "    from rekall.temporal_predicates import overlaps, before, after\n",
    "    \n",
    "    SEGMENT_LENGTH=30\n",
    "    OVERLAP_LAX=60\n",
    "    HOST_GUEST_GAP=120\n",
    "    MIN_LENGTH=240\n",
    "    SMALL_FACE_THRESHOLD=0.3\n",
    "    MIN_GUEST_TIME_RATIO=0.35\n",
    "    MAX_SMALL_GUEST_RATIO=0.7\n",
    "    \n",
    "    fuzzy_overlap = or_preds(overlaps(), before(max_dist=OVERLAP_LAX), after(max_dist=OVERLAP_LAX))\n",
    "    \n",
    "    interview_candidates = hosts.merge(guest, T(fuzzy_overlap), time_window=OVERLAP_LAX).temporal_coalesce()\n",
    "    interviews = interview_candidates.temporal_coalesce(\n",
    "        epsilon=HOST_GUEST_GAP\n",
    "    ).filter_size(min_size=MIN_LENGTH\n",
    "    ).minus(commercials\n",
    "    ).filter_size(min_size=MIN_LENGTH)\n",
    "\n",
    "    def select_second(p):\n",
    "        return p[1]\n",
    "    \n",
    "    # Interview<Guest<height>>\n",
    "    interview_with_guest = interviews.collect_by_interval(\n",
    "        guest,\n",
    "        T(overlaps()),\n",
    "        filter_empty=True,\n",
    "        time_window=0,\n",
    "    ).map_payload(\n",
    "        select_second)\n",
    "\n",
    "    def total_time(intervals):\n",
    "        return intervals.fold(lambda s, i: s+i.length(), 0)\n",
    "    \n",
    "    def filter_time(interview):\n",
    "        guest = interview.payload\n",
    "        small_guest = guest.filter_size(max_size=SMALL_FACE_THRESHOLD, axis='Y')\n",
    "        small_guest_time = total_time(small_guest)\n",
    "        total_guest_time = total_time(guest)\n",
    "        segment_time = interview.length()\n",
    "        return (total_guest_time / segment_time > MIN_GUEST_TIME_RATIO and\n",
    "                small_guest_time / total_guest_time < MAX_SMALL_GUEST_RATIO)\n",
    "    # Interview<Guest<height>>\n",
    "    interviews = interview_with_guest.filter(filter_time)\n",
    "\n",
    "    # Guest<height>\n",
    "    guest_in_interviews = guest.filter_against(interviews, T(overlaps()), time_window=0)\n",
    "    # HostAndGuest<(Host, Guest)>\n",
    "    guest_with_host = guest_in_interviews.join(\n",
    "        hosts,\n",
    "        T(overlaps()),\n",
    "        lambda guest, host: [Interval3D(overlap_bound(guest.t, host.t), payload=(guest, host))],\n",
    "        time_window=0)\n",
    "    guest_only = guest_in_interviews.minus(guest_with_host)\n",
    "\n",
    "    hosts_in_interviews = hosts.filter_against(interviews, T(overlaps()), time_window=0)\n",
    "    hosts_only = hosts_in_interviews.minus(guest_with_host)\n",
    "    \n",
    "    interview_with_metadata = interviews.collect_by_interval(\n",
    "        guest_only,\n",
    "        T(overlaps()),\n",
    "        filter_empty=False,\n",
    "        time_window=0\n",
    "    ).map_payload(select_second).collect_by_interval(\n",
    "        hosts_only,\n",
    "        T(overlaps()),\n",
    "        filter_empty=False,\n",
    "        time_window=0\n",
    "    ).collect_by_interval(\n",
    "        guest_with_host,\n",
    "        T(overlaps()),\n",
    "        filter_empty=False,\n",
    "        time_window=0\n",
    "    ).map_payload(lambda p: (p[0][0],p[0][1],p[1]))\n",
    "    \n",
    "    return interview_with_metadata\n",
    "\n",
    "def get_interviews_for_vids(vids):\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    people_to_intervals = get_person_intervals_in_vids(HOST_LIST + GUEST_LIST, vids, 0.7,0.2)\n",
    "    hosts = DomainIntervalCollection({})\n",
    "    for host_name in HOST_LIST:\n",
    "        hosts = hosts.union(people_to_intervals[host_name])\n",
    "    commercials = get_commercial_intervals_in_vids(vids)\n",
    "    ret = DomainIntervalCollection({})\n",
    "    for guest_name in tqdm(GUEST_LIST):\n",
    "        guest = people_to_intervals[guest_name]\n",
    "        interviews = interview_query(guest, hosts, commercials)\n",
    "        ret = ret.union(interviews)\n",
    "    return ret       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on a few videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T20:18:57.723918Z",
     "start_time": "2019-03-14T20:18:55.608387Z"
    }
   },
   "outputs": [],
   "source": [
    "vids = VIDEOS[::10000]\n",
    "answer = get_interviews_for_vids(vids)\n",
    "display_result(convert_to_1d_collection(second_to_frame_collection(answer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run On All of TVNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T08:45:50.550091Z",
     "start_time": "2019-03-14T08:45:37.500180Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "from esper.rekall_parallel import get_runtime_for_ipython_cluster\n",
    "import pickle\n",
    "c = ipp.Client(profile='local')\n",
    "rt = get_runtime_for_ipython_cluster(c)\n",
    "\n",
    "vids = VIDEOS[:10000]\n",
    "answer,_ = rt.run(get_interviews_for_vids, vids, randomize=False, chunksize=20, progress=True)\n",
    "# pickle.dump(answer, open('../data/interviews/interviews{0}-{1}.pkl'.format(vids[0],vids[-1]), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T20:19:17.527168Z",
     "start_time": "2019-03-14T20:19:05.045969Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "from esper.rekall_parallel import get_runtime_for_ipython_cluster\n",
    "import pickle\n",
    "c = ipp.Client(profile='local')\n",
    "rt = get_runtime_for_ipython_cluster(c)\n",
    "\n",
    "answer = topN(rt.get_result_iterator(get_interviews_for_vids, VIDEOS, randomize=True),n=25)\n",
    "display_result(convert_to_1d_collection(second_to_frame_collection(answer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faces in a Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T20:19:49.125527Z",
     "start_time": "2019-03-14T20:19:44.776092Z"
    }
   },
   "outputs": [],
   "source": [
    "VIDEOS = sorted([v.id for v in Video.objects.all()])\n",
    "\n",
    "def get_faces_in_a_row_for_vids(vids):\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    from rekall.interval_set_3d_utils import P, XY, and_preds\n",
    "    from rekall.bbox_predicates import left_of, same_value\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    MIN_NUM_FACES = 10\n",
    "    MIN_HEIGHT = 0.1\n",
    "    EPSILON = 0.05\n",
    "    \n",
    "    qs = Face.objects.filter(frame__video_id__in=vids).annotate(\n",
    "        video_id=F(\"frame__video_id\"),\n",
    "        min_frame=F(\"frame__number\"),\n",
    "        max_frame=F(\"frame__number\") + 1,\n",
    "        height=F('bbox_y2')-F('bbox_y1'),\n",
    "    ).filter(height__gte=MIN_HEIGHT)\n",
    "    faces = DomainIntervalCollection.from_django_qs(qs, DomainIntervalCollection.django_bbox_default_schema(),\n",
    "                                            progress=True)\n",
    "    def has_enough_faces(n):\n",
    "        def pred(faces):\n",
    "            return faces.size() >= n\n",
    "        return pred\n",
    "    \n",
    "    def get_pattern(n):\n",
    "        assert(n>1)\n",
    "        constraints = []\n",
    "        for i in range(n-1):\n",
    "            name1 = str(i)\n",
    "            name2 = str(i+1)\n",
    "            constraints.append(([name1, name2],[XY(\n",
    "                and_preds(\n",
    "                    left_of(),\n",
    "                    same_value('y1', epsilon=EPSILON),\n",
    "                    same_value('y2', epsilon=EPSILON)))]))\n",
    "        return constraints          \n",
    "    \n",
    "    def faces_aligned():\n",
    "        def pred(faces):\n",
    "            pattern = get_pattern(faces.size())\n",
    "            return len(faces.match(pattern, exact=True)) > 0\n",
    "        return pred\n",
    "        \n",
    "    commercials = get_commercial_intervals_in_vids(vids, in_seconds=False)\n",
    "    \n",
    "    aligned_faces_in_frames = faces.minus(commercials).group_by_time().filter(P(and_preds(\n",
    "        has_enough_faces(MIN_NUM_FACES),\n",
    "        faces_aligned())))\n",
    "    \n",
    "    return aligned_faces_in_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on a few videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T20:19:54.931172Z",
     "start_time": "2019-03-14T20:19:50.380532Z"
    }
   },
   "outputs": [],
   "source": [
    "vids = VIDEOS[::10003]\n",
    "answer = get_faces_in_a_row_for_vids(vids)\n",
    "display_result(convert_to_1d_collection(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run On All of TVNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T20:20:34.960593Z",
     "start_time": "2019-03-14T20:20:03.119719Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "from esper.rekall_parallel import get_runtime_for_ipython_cluster\n",
    "import pickle\n",
    "c = ipp.Client(profile='local')\n",
    "rt = get_runtime_for_ipython_cluster(c)\n",
    "\n",
    "vids = VIDEOS[4::100]\n",
    "answer,_ = rt.run(get_faces_in_a_row_for_vids, vids, randomize=False, chunksize=15, progress=True)\n",
    "print(\"Total results:\", sum(answer.size().values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T20:20:38.160662Z",
     "start_time": "2019-03-14T20:20:38.056131Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_vids(c, vids=None):\n",
    "    from rekall.video_interval_collection_3d import VideoIntervalCollection3D\n",
    "    if vids is None or len(vids)==0:\n",
    "        return c\n",
    "    d = c.get_allintervals()\n",
    "    ret = {}\n",
    "    for v in vids:\n",
    "        if v in d:\n",
    "            ret[v] = d[v]\n",
    "    return VideoIntervalCollection3D(ret)\n",
    "\n",
    "display_result(convert_to_1d_collection(filter_vids(answer,[])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donald Trump on All Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T20:20:54.813689Z",
     "start_time": "2019-03-14T20:20:54.553676Z"
    }
   },
   "outputs": [],
   "source": [
    "TRUMP_FACE_LABELER_IDS = get_name_to_labeler_id(['donald trump'])['donald trump']\n",
    "def get_video_ids_for_dates(dates):\n",
    "    assert(len(dates)>0)\n",
    "    import datetime as dt\n",
    "    from django.db.models import Q\n",
    "    from query.models import Video\n",
    "    \n",
    "    one_day = dt.timedelta(days=1)\n",
    "    f = None\n",
    "    for d in dates:\n",
    "        new_term = Q(time__gte=d) & Q(time__lt=d+one_day)\n",
    "        if f is None:\n",
    "            f = new_term\n",
    "        else:\n",
    "            f = f | new_term\n",
    "    return [v.id for v in Video.objects.filter(duplicate=False, corrupted=False).filter(f)]\n",
    "    \n",
    "def get_donald_faces_on_dates(dates, probability=0.7, min_height=None):\n",
    "    SAMPLING_RATE = 3.0\n",
    "    \n",
    "    from query.models import FaceIdentity\n",
    "    from django.db.models import F, FloatField\n",
    "    from django.db.models.functions import Cast\n",
    "    from rekall.runtime import Runtime\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "\n",
    "    vids = get_video_ids_for_dates(dates)\n",
    "    print(\"{0} videos found\".format(len(vids)))\n",
    "    \n",
    "    def get_faces_for_vid(vs):\n",
    "        face_id_qs = FaceIdentity.objects.filter(\n",
    "            probability__gte=probability,\n",
    "            face__frame__video_id__in=vs,\n",
    "            face__frame__shot_boundary=False,\n",
    "            labeler_id__in=TRUMP_FACE_LABELER_IDS,\n",
    "        ).annotate(\n",
    "            height=F('face__bbox_y2')-F('face__bbox_y1'),\n",
    "            video_id=F('face__frame__video_id'),\n",
    "            start=Cast(F('face__frame__number') / F('face__frame__video__fps'),\n",
    "                     FloatField()),\n",
    "            end=Cast(F('face__frame__number') / F('face__frame__video__fps') + SAMPLING_RATE,\n",
    "                     FloatField()),\n",
    "            x1=F('face__bbox_x1'),\n",
    "            x2=F('face__bbox_x2'),\n",
    "            y1=F('face__bbox_y1'),\n",
    "            y2=F('face__bbox_y2')\n",
    "        )\n",
    "        if min_height is not None:\n",
    "            face_id_qs = face_id_qs.filter(height__gte=min_height)\n",
    "        \n",
    "        faces = DomainIntervalCollection.from_django_qs(face_id_qs, {\n",
    "            't1':'start',\n",
    "            't2':'end',\n",
    "            'x1':'x1','x2':'x2','y1':'y1','y2':'y2',\n",
    "            }, progress=False)\n",
    "        return faces\n",
    "    if len(vids) == 0:\n",
    "        return DomainIntervalCollection({})\n",
    "    # Read from Django in small batches, otherwise it gets stuck\n",
    "    faces,_ = Runtime.inline().run(get_faces_for_vid, vids, chunksize=10, progress=True)\n",
    "    return faces\n",
    "\n",
    "# Time dimension will be unix timestamp\n",
    "# Outputs one IntervalSet3D<VideoID, ChannelName>\n",
    "def convert_to_absolute_time_and_add_channel(collection):\n",
    "    from query.models import Video\n",
    "    from rekall.interval_set_3d import IntervalSet3D, Interval3D\n",
    "    \n",
    "    vids = collection.get_grouped_intervals().keys()\n",
    "    vs = Video.objects.filter(id__in=vids)\n",
    "    # Seconds since Unix Epoch\n",
    "    start_time_map = {v.id: v.time.timestamp() for v in vs}\n",
    "    channel_map = {v.id: v.channel.name for v in vs}\n",
    "    \n",
    "    faces = collection.add_domain_to_payload().get_flattened_intervalset()\n",
    "    \n",
    "    # Interval<VideoID, ChannelName>\n",
    "    def convert(interval):\n",
    "        vid = interval.payload[1]\n",
    "        start = start_time_map[vid]\n",
    "        channel = channel_map[vid]\n",
    "        return Interval3D((interval.t[0]+start, interval.t[1]+start),\n",
    "                          interval.x, interval.y, payload=(vid, channel))\n",
    "    return faces.map(convert)\n",
    "\n",
    "# intervals: IntervalSet<(VideoID,...)>, in absolute time\n",
    "# Outputs a collection grouped by video id, in relative time (seconds)\n",
    "def group_by_video_and_use_relative_time(intervals):\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "    from rekall.interval_set_3d import IntervalSet3D\n",
    "    \n",
    "    by_vids = DomainIntervalCollection.from_intervalset(intervals, lambda i: i.payload[0])\n",
    "    vids = by_vids.get_grouped_intervals().keys()\n",
    "    start_time_map = {v.id: v.time.timestamp() for v in Video.objects.filter(id__in=vids)}\n",
    "    \n",
    "    def convert_time(i):\n",
    "        vid = i.payload[0]\n",
    "        start = start_time_map[vid]\n",
    "        j = i.copy()\n",
    "        j.t = i.t[0]-start, i.t[1]-start\n",
    "        return j\n",
    "            \n",
    "    return by_vids.map(convert_time)\n",
    "\n",
    "# Returns Interval<Faces>\n",
    "def donald_on_all_channels(dates):\n",
    "    MIN_FACE_PROB = 0.7\n",
    "    MIN_FACE_HEIGHT = 0.3\n",
    "    MIN_NUM_CHANNELS = 3\n",
    "    \n",
    "    from rekall.temporal_predicates import overlaps\n",
    "    from rekall.interval_set_3d import Interval3D, IntervalSet3D\n",
    "    from rekall.interval_set_3d_utils import T, overlap_bound\n",
    "    from rekall.domain_interval_collection import DomainIntervalCollection\n",
    "\n",
    "    faces = get_donald_faces_on_dates(\n",
    "        dates,\n",
    "        probability=MIN_FACE_PROB,\n",
    "        min_height=MIN_FACE_HEIGHT)\n",
    "    print(\"got faces\")\n",
    "    \n",
    "    # Face<VideoID, Channel>\n",
    "    faces_with_channel = convert_to_absolute_time_and_add_channel(faces)\n",
    "    print(\"converted to absolute time\")\n",
    "    \n",
    "    faces_per_channel = DomainIntervalCollection.from_intervalset(faces_with_channel, lambda i: i.payload[1])\n",
    "    \n",
    "    if len(faces_per_channel.get_grouped_intervals()) < MIN_NUM_CHANNELS:\n",
    "        return IntervalSet3D([])\n",
    "    \n",
    "    output = None\n",
    "    for channel, faces in faces_per_channel.get_grouped_intervals().items():\n",
    "        if output is None:\n",
    "            output = faces.map(lambda i: Interval3D(i.t, payload=[i]))\n",
    "        else:\n",
    "            output = output.join(\n",
    "                faces,\n",
    "                T(overlaps()),\n",
    "                lambda f1, f2: [\n",
    "                    Interval3D(overlap_bound(f1.t,f2.t), payload=f1.payload + [f2])\n",
    "                ],\n",
    "                time_window=0,\n",
    "            )\n",
    "        print(\"{0} intervals found\".format(output.size()))\n",
    "    if output is None:\n",
    "        return IntervalSet3D([])\n",
    "    output = output.map_payload(lambda p: group_by_video_and_use_relative_time(IntervalSet3D(p)))\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run on a few dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T20:20:59.909380Z",
     "start_time": "2019-03-14T20:20:55.452021Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "NUM_DATES=1\n",
    "dates = [datetime.date(2017,1,20)+ i*datetime.timedelta(days=1) for i in range(NUM_DATES)]\n",
    "answer = donald_on_all_channels(dates)\n",
    "\n",
    "display_result(convert_to_1d_collection(second_to_frame_collection(answer.get_intervals()[0].payload)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on one Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T20:21:29.393781Z",
     "start_time": "2019-03-14T20:21:03.052743Z"
    }
   },
   "outputs": [],
   "source": [
    "YEAR = 2015\n",
    "is_leap = YEAR % 4 == 0 and (YEAR % 100 != 0 or YEAR % 400 == 0)\n",
    "start = datetime.date(YEAR,1,1)\n",
    "delta = datetime.timedelta(days=1)\n",
    "dates = [start + delta * i for i in range(366 if is_leap else 365)]\n",
    "\n",
    "import ipyparallel as ipp\n",
    "from esper.rekall_parallel import get_runtime_for_ipython_cluster\n",
    "import pickle\n",
    "c = ipp.Client(profile='local')\n",
    "rt = get_runtime_for_ipython_cluster(c)\n",
    "\n",
    "answer,_ = rt.run(donald_on_all_channels, dates, randomize=False, chunksize=10, progress=True)\n",
    "print(\"Total results:\", answer.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T08:53:31.482365Z",
     "start_time": "2019-03-05T08:44:57.464933Z"
    }
   },
   "outputs": [],
   "source": [
    "YEARS = range(2009,2019)\n",
    "dates = []\n",
    "for y in YEARS:\n",
    "    is_leap = y % 4 == 0 and (y % 100 != 0 or y % 400 == 0)\n",
    "    start = datetime.date(y,1,1)\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    dates.extend([start + delta * i for i in range(366 if is_leap else 365)])\n",
    "\n",
    "import ipyparallel as ipp\n",
    "from esper.rekall_parallel import get_runtime_for_ipython_cluster\n",
    "import pickle\n",
    "c = ipp.Client(profile='local')\n",
    "rt = get_runtime_for_ipython_cluster(c)\n",
    "\n",
    "answer,_ = rt.run(donald_on_all_channels, dates, randomize=False, chunksize=5, progress=True)\n",
    "print(\"Total results:\", answer.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T07:18:38.054259Z",
     "start_time": "2019-02-28T07:18:35.064392Z"
    }
   },
   "outputs": [],
   "source": [
    "vids = [763, 3769, 5281, 8220, 9901, 12837, 13141, 26386, 33004, 33004, 34642, 38275, 42756, 50164, 50164, 50164, 50164, 50164, 50164, 50164, 52075, 52945, 54377, 54377, 59122, 59122, 59398, 59398, 59398, 59398]\n",
    "\n",
    "answer = get_person_intervals_in_vids(HOST_LIST + GUEST_LIST, vids, 0.7,0.2)\n",
    "display_result(convert_to_1d_collection(second_to_frame_collection(answer['bernie sanders'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T01:17:26.660454Z",
     "start_time": "2019-02-28T01:17:26.572442Z"
    }
   },
   "outputs": [],
   "source": [
    "display_result(convert_to_1d_collection(second_to_frame_collection(answer['jake tapper'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T01:21:01.130353Z",
     "start_time": "2019-02-28T01:21:00.836905Z"
    }
   },
   "outputs": [],
   "source": [
    "answer = get_interviews_for_vids(vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T00:52:35.112140Z",
     "start_time": "2019-02-28T00:52:31.859291Z"
    }
   },
   "outputs": [],
   "source": [
    "display_result(convert_to_1d_collection(second_to_frame_collection(answer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T21:03:10.357104Z",
     "start_time": "2019-02-27T21:03:10.249785Z"
    }
   },
   "outputs": [],
   "source": [
    "ls=[l.name for l in Labeler.objects.all() if l.name.startswith('face-identity:') or l.name.startswith('face-identity-converted:') or l.name.startswith('face-identity-uncommon:')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T21:04:22.254636Z",
     "start_time": "2019-02-27T21:04:22.229695Z"
    }
   },
   "outputs": [],
   "source": [
    "ls=[l.split(':')[1] for l in ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T21:14:30.437522Z",
     "start_time": "2019-02-27T21:14:30.401923Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T21:05:37.415053Z",
     "start_time": "2019-02-27T21:05:37.390264Z"
    }
   },
   "outputs": [],
   "source": [
    "for g in GUEST_LIST:\n",
    "    if g not in ls:\n",
    "        print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T21:05:50.887453Z",
     "start_time": "2019-02-27T21:05:50.862528Z"
    }
   },
   "outputs": [],
   "source": [
    "for h in HOST_LIST:\n",
    "    if h not in ls:\n",
    "        print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T21:11:43.221334Z",
     "start_time": "2019-02-27T21:11:43.192756Z"
    }
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T22:50:40.997595Z",
     "start_time": "2019-02-27T22:50:40.970892Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted(HOST_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T01:23:29.275271Z",
     "start_time": "2019-02-28T01:23:29.192659Z"
    }
   },
   "outputs": [],
   "source": [
    "interviews = LabeledInterview.objects \\\n",
    "        .annotate(fps=F('video__fps')) \\\n",
    "        .annotate(min_frame=F('fps') * F('start')) \\\n",
    "        .annotate(max_frame=F('fps') * F('end')) \\\n",
    "        .filter(guest1=\"bernie sanders\", original=True)\n",
    "print([i.video.id for i in interviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T01:24:43.118752Z",
     "start_time": "2019-02-28T01:24:43.093609Z"
    }
   },
   "outputs": [],
   "source": [
    "len(vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T01:38:27.632752Z",
     "start_time": "2019-02-28T01:38:27.607096Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.get_allintervals()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T03:44:01.350625Z",
     "start_time": "2019-02-28T03:44:01.327596Z"
    }
   },
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T01:45:05.005193Z",
     "start_time": "2019-02-28T01:45:04.979041Z"
    }
   },
   "outputs": [],
   "source": [
    "len(VIDEOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T02:42:51.752930Z",
     "start_time": "2019-02-28T02:42:51.726826Z"
    }
   },
   "outputs": [],
   "source": [
    "VIDEOS[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T02:44:17.533935Z",
     "start_time": "2019-02-28T02:44:17.487130Z"
    }
   },
   "outputs": [],
   "source": [
    "Video.objects.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T07:39:19.313069Z",
     "start_time": "2019-02-28T07:39:19.009727Z"
    }
   },
   "outputs": [],
   "source": [
    "from rekall.video_interval_collection_3d import VideoIntervalCollection3D\n",
    "vids = [188346]\n",
    "people_to_intervals = get_person_intervals_in_vids(HOST_LIST + GUEST_LIST, vids, 0.7,0.2)\n",
    "hosts = VideoIntervalCollection3D({})\n",
    "for host_name in HOST_LIST:\n",
    "    hosts = hosts.union(people_to_intervals[host_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T07:39:20.189493Z",
     "start_time": "2019-02-28T07:39:20.045349Z"
    }
   },
   "outputs": [],
   "source": [
    "display_result(convert_to_1d_collection(second_to_frame_collection(hosts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T07:34:10.805294Z",
     "start_time": "2019-02-28T07:34:09.701833Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "a = pickle.load(open('../data/interviews/paper/interview_10y-all.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T07:35:21.315585Z",
     "start_time": "2019-02-28T07:35:21.279262Z"
    }
   },
   "outputs": [],
   "source": [
    "a['John Kasich'][188346]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T07:35:49.240074Z",
     "start_time": "2019-02-28T07:35:49.207268Z"
    }
   },
   "outputs": [],
   "source": [
    "VIDEOS.index(188346)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T07:42:03.133452Z",
     "start_time": "2019-02-28T07:42:03.091534Z"
    }
   },
   "outputs": [],
   "source": [
    "people_to_intervals['john kasich'].get_allintervals()[188346]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T07:59:15.948107Z",
     "start_time": "2019-02-28T07:59:15.905449Z"
    }
   },
   "outputs": [],
   "source": [
    "Video.objects.get(id=188346).fps * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T07:57:22.887515Z",
     "start_time": "2019-02-28T07:57:22.796263Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_person_intervals_in_vids_frames(person_names, vids, probability=0.7, min_height=None):\n",
    "    from query.models import FaceIdentity\n",
    "    from django.db.models import F,Q\n",
    "    from rekall.video_interval_collection_3d import VideoIntervalCollection3D\n",
    "    from rekall.interval_set_3d import Interval3D\n",
    "    from rekall.interval_set_3d_utils import P\n",
    "    \n",
    "    SAMPLE_RATE = 3 # Every 3s\n",
    "\n",
    "    lids = []\n",
    "    for n in person_names:\n",
    "        lids.extend(NAME_TO_LABELER_ID[n])\n",
    "    \n",
    "    face_id_qs = FaceIdentity.objects.filter(\n",
    "        probability__gte=probability,\n",
    "        face__frame__video_id__in=vids,\n",
    "        face__frame__shot_boundary=False,\n",
    "        labeler_id__in=lids,\n",
    "    ).annotate(\n",
    "        height=F('face__bbox_y2')-F('face__bbox_y1'),\n",
    "        labeler_name=F('labeler__name'),\n",
    "        video_id=F('face__frame__video_id'),\n",
    "        frame_number=F('face__frame__number'),\n",
    "        x1=F('face__bbox_x1'),\n",
    "        x2=F('face__bbox_x2'),\n",
    "        y1=F('face__bbox_y1'),\n",
    "        y2=F('face__bbox_y2'),\n",
    "    )\n",
    "    if min_height is not None:\n",
    "        face_id_qs = face_id_qs.filter(height__gte=min_height)\n",
    "    \n",
    "    total = face_id_qs.count()\n",
    "    faces = VideoIntervalCollection3D.from_django_qs(face_id_qs, {\n",
    "        't1':'frame_number',\n",
    "        't2':'frame_number',\n",
    "        'x1':'x1','x2':'x2','y1':'y1','y2':'y2',\n",
    "    }, with_payload=lambda row: row.labeler_name.split(':')[1], progress=True, total=total)\n",
    "\n",
    "    fps_map = get_fps_map(set(faces.get_allintervals().keys()))\n",
    "    names_to_collection = {}\n",
    "    for n in person_names:\n",
    "        faces_one_person = faces.filter(P(lambda p: p==n))\n",
    "        output = {}\n",
    "        for vid, intervals in faces_one_person.get_allintervals().items():\n",
    "            fps = fps_map[vid]\n",
    "            eps = fps * SAMPLE_RATE\n",
    "            output[vid] = intervals.temporal_coalesce(epsilon=eps)\n",
    "        names_to_collection[n] = VideoIntervalCollection3D(output)\n",
    "    return names_to_collection\n",
    "jk = get_person_intervals_in_vids_frames(['john kasich'], [188346], probability=0.7, min_height=0.2)\n",
    "jk['john kasich'].get_allintervals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T08:58:16.863325Z",
     "start_time": "2019-02-28T08:58:16.834499Z"
    }
   },
   "outputs": [],
   "source": [
    "len(answer.get_allintervals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T23:48:16.173384Z",
     "start_time": "2019-02-28T23:48:16.141768Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.get_allintervals()[42341].map_payload(lambda _:None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T23:50:38.609842Z",
     "start_time": "2019-02-28T23:50:38.576733Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.get_allintervals()[42341].split(lambda i:i.payload[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T23:56:59.836591Z",
     "start_time": "2019-02-28T23:56:59.800689Z"
    }
   },
   "outputs": [],
   "source": [
    "len(vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:35:00.994867Z",
     "start_time": "2019-03-01T00:35:00.967232Z"
    }
   },
   "outputs": [],
   "source": [
    "keys = answer.get_allintervals().keys()\n",
    "[(k, answer.get_allintervals()[k].)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:45:11.222317Z",
     "start_time": "2019-03-01T00:45:11.185658Z"
    }
   },
   "outputs": [],
   "source": [
    "def discard(p):\n",
    "    return None\n",
    "frame_to_second_collection(answer).get_allintervals()[128907].map_payload(discard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T22:13:26.569934Z",
     "start_time": "2019-03-04T22:13:26.540060Z"
    }
   },
   "outputs": [],
   "source": [
    "Video.objects.get(id=1).time.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T22:52:18.905244Z",
     "start_time": "2019-03-04T22:52:18.794925Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "date = datetime.date(2016,12,16)\n",
    "vs=Video.objects.filter(time__gte=date, time__lt=date+datetime.timedelta(days=1), duplicate=False, corrupted=False)\n",
    "vs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T22:52:19.624643Z",
     "start_time": "2019-03-04T22:52:19.554762Z"
    }
   },
   "outputs": [],
   "source": [
    "[v.time for v in vs.filter(channel_id=1).order_by('time')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T19:44:50.942701Z",
     "start_time": "2019-03-04T19:44:50.919155Z"
    }
   },
   "outputs": [],
   "source": [
    "Labeler.objects.filter(name__contains='donald trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T21:57:16.956482Z",
     "start_time": "2019-03-04T21:57:16.928633Z"
    }
   },
   "outputs": [],
   "source": [
    "TRUMP_FACE_LABELER_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T19:53:32.619923Z",
     "start_time": "2019-03-04T19:50:21.901532Z"
    }
   },
   "outputs": [],
   "source": [
    "FaceIdentity.objects.filter(labeler_id=TRUMP_FACE_LABELER_ID, face__frame__video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T22:29:05.758866Z",
     "start_time": "2019-03-04T22:29:05.702249Z"
    }
   },
   "outputs": [],
   "source": [
    "vids = list(range(10))\n",
    "probability=0.7\n",
    "face_id_qs = FaceIdentity.objects.filter(\n",
    "    probability__gte=probability,\n",
    "    face__frame__video_id__in=vids,\n",
    "    face__frame__shot_boundary=False,\n",
    "    labeler_id__in=[419],\n",
    ").annotate(\n",
    "    height=F('face__bbox_y2')-F('face__bbox_y1'),\n",
    "    labeler_name=F('labeler__name'),\n",
    "    video_id=F('face__frame__video_id'),\n",
    "    start=Cast(F('face__frame__number') / F('face__frame__video__fps'),\n",
    "                 FloatField()),\n",
    "    end=F('start') + 3.0,\n",
    "    x1=F('face__bbox_x1'),\n",
    "    x2=F('face__bbox_x2'),\n",
    "    y1=F('face__bbox_y1'),\n",
    "    y2=F('face__bbox_y2'),\n",
    "    time=F('face__frame__video__time')\n",
    ").filter(height__gte=0.4)\n",
    "face_id_qs[0].face.frame.video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T22:30:15.139674Z",
     "start_time": "2019-03-04T22:30:15.113202Z"
    }
   },
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T23:08:21.947389Z",
     "start_time": "2019-03-04T23:08:21.921346Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.get_intervals()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T23:13:44.146732Z",
     "start_time": "2019-03-04T23:13:44.120946Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.get_intervals()[0].payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T23:55:32.758260Z",
     "start_time": "2019-03-04T23:55:32.731525Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted(answer.get_allintervals().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T23:46:44.301588Z",
     "start_time": "2019-03-04T23:46:44.274165Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.get_allintervals()['2009-10-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T21:17:15.786572Z",
     "start_time": "2019-03-11T21:17:15.739601Z"
    }
   },
   "outputs": [],
   "source": [
    "display_result(convert_to_1d_collection(second_to_frame_collection(sort_by_video(answer.get_intervals()[1].payload))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
