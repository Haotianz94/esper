{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Querying-for-Interviews-with-Person-X\" data-toc-modified-id=\"Querying-for-Interviews-with-Person-X-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Querying for Interviews with Person X</a></span><ul class=\"toc-item\"><li><span><a href=\"#Interviews-with-Bernie-Sanders\" data-toc-modified-id=\"Interviews-with-Bernie-Sanders-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Interviews with Bernie Sanders</a></span></li><li><span><a href=\"#Interviews-with-Kellyanne-Conway-and-John-McCain\" data-toc-modified-id=\"Interviews-with-Kellyanne-Conway-and-John-McCain-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Interviews with Kellyanne Conway and John McCain</a></span></li><li><span><a href=\"#Modify-after-detecting-fixed-stride-faces-and-new-identity-labeling-model\" data-toc-modified-id=\"Modify-after-detecting-fixed-stride-faces-and-new-identity-labeling-model-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Modify after detecting fixed stride faces and new identity labeling model</a></span></li></ul></li><li><span><a href=\"#Now-let's-try-to-detect-interviews-in-the-whole-dataset\" data-toc-modified-id=\"Now-let's-try-to-detect-interviews-in-the-whole-dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Now let's try to detect interviews in the whole dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Detect-all-the-interviews-with-2016-presidential-candidates\" data-toc-modified-id=\"Detect-all-the-interviews-with-2016-presidential-candidates-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Detect all the interviews with 2016 presidential candidates</a></span></li><li><span><a href=\"#Visulaize-result\" data-toc-modified-id=\"Visulaize-result-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Visulaize result</a></span></li><li><span><a href=\"#Analyze-result-stats-(create-csv-for-tablao)\" data-toc-modified-id=\"Analyze-result-stats-(create-csv-for-tablao)-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Analyze result stats (create csv for tablao)</a></span></li><li><span><a href=\"#Interview-montage\" data-toc-modified-id=\"Interview-montage-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Interview montage</a></span></li><li><span><a href=\"#Interview-validation\" data-toc-modified-id=\"Interview-validation-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Interview validation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-gt-from-csv\" data-toc-modified-id=\"Create-gt-from-csv-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Create gt from csv</a></span></li><li><span><a href=\"#Validate-interview-of-person-X\" data-toc-modified-id=\"Validate-interview-of-person-X-2.5.2\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>Validate interview of person X</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T03:51:43.687640Z",
     "start_time": "2019-01-17T03:51:42.984203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports. Run this first!\n",
    "\n",
    "from query.models import LabeledInterview, LabeledPanel, LabeledCommercial, Video, FaceIdentity, Face\n",
    "from esper.rekall import *\n",
    "from rekall.temporal_predicates import *\n",
    "from rekall.spatial_predicates import *\n",
    "from rekall.interval_list import IntervalList\n",
    "from esper.prelude import esper_widget\n",
    "#from esper.captions import topic_search\n",
    "from django.db.models import FloatField\n",
    "\n",
    "sandbox_videos = [529, 763, 2648, 3459, 3730, 3769, 3952, 4143, 4611, 5281, 6185, 7262, 8220,\n",
    "    8697, 8859, 9215, 9480, 9499, 9901, 10323, 10335, 11003, 11555, 11579, 11792,\n",
    "    12837, 13058, 13141, 13247, 13556, 13827, 13927, 13993, 14482, 15916, 16215,\n",
    "    16542, 16693, 16879, 17458, 17983, 19882, 19959, 20380, 20450, 23181, 23184,\n",
    "    24193, 24847, 24992, 25463, 26386, 27188, 27410, 29001, 31378, 32472, 32996,\n",
    "    33004, 33387, 33541, 33800, 34359, 34642, 36755, 37107, 37113, 37170, 38275,\n",
    "    38420, 40203, 40856, 41480, 41725, 42756, 45472, 45645, 45655, 45698, 48140,\n",
    "    49225, 49931, 50164, 50561, 51175, 52075, 52749, 52945, 53355, 53684, 54377,\n",
    "    55711, 57384, 57592, 57708, 57804, 57990, 59122, 59398, 60186]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying for Interviews with Person X\n",
    "\n",
    "We have an annotated sandbox of panels, interviews, and commercials (`query_labeledpanel`, `query_labeledinterview`, `query_commercial`). In this notebook we'll try to use write queries for these concepts and compare the results against our labels.\n",
    "\n",
    "A few notes about the panels:\n",
    "* Panel segments go from the introduction of panelists to the shot where the host says \"thank you\" or \"goodbye\" to the panelists. Sometimes the camera will cut wide and show all the panelists before a commercial break; such shots are *not* included in the labeled segments.\n",
    "* Panel segments are split up by commercials (i.e., if the same panel appears before and after a commercial break, that will be two panel segments).\n",
    "* Panels segments do not include segments where the host is just cutting to multiple reporters out in the field to cover some news story.\n",
    "\n",
    "A few notes about the interviews. See the third bullet point in particular.\n",
    "* Interview segments go from the first shot of the guest to where the host thanks the guest. Sometimes the host thanks the guest while the guest is on screen, and sometimes the host thanks the guest off-screen. In the former case, the segment continues until the guest is no longer on screen; in the latter case, the segment stops when the host changes the subject after thanking the guest.\n",
    "* Sometimes the host doesn't thank the guest; in this case, the segment ends when the guest is no longer on screen or when the host changes the subject.\n",
    "* **Interviews with analysts and correspondents from the same network are *not* included. This is to differentiate between the typical interview and \"interviews\" where the guest is just presenting a news segment.**\n",
    "* Interviews with reporters from the same network are also usually not included, *unless* the format of the interview is sufficiently different from the typical \"here's a reporter to tell you the news\" format. This is a judgment call on my (Dan Fu) part.\n",
    "\n",
    "This dataset also includes extra annotation of interviews with Kellyanne Conway, Bernie Sanders, and John McCain.\n",
    "* These interview segments include **any** segment where Kellyanne Conway, Bernie Sanders, or John McCain appear and are being interviewed. This includes segments during commercials or short clips where an interview of one of them is being played on another channel or show.\n",
    "* These segments also include clips where the guest appears for a few seconds as a \"preview\" before a commercial break.\n",
    "* Each of these segments is annotated with the name of the guest(s) and interviewer(s).\n",
    "\n",
    "A few notes about the commercials.\n",
    "* Commercial segments go from the beginning of the commercial break to the end of the commercial break. Sometimes networks will put in a segment from the network to let the viewers know that the commercial break is ending (think \"this is CNN, the must trusted name in news\" segment). Such segments are included in the commercial segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some statistics. Suppose we have a set of intervals `query` that represent our query, and a set of intervals `ground_truth` that represent our ground truth. We are interested in four statistics:\n",
    "* **precision**: This is your standard definition of precision, computed over the intervals: `sum(overlap(query, ground_truth)) / sum(query)`\n",
    "* **recall**: This is your standard definition of recall, computed over the intervals: `sum(overlap(query, ground_truth)) / sum(ground_truth)`\n",
    "* **precision_per_item**: We may also be interested in *how many* segments we hit. How many segments in `query` overlap with *any* segment in `ground_truth`? This is `sum(count(overlap(query, ground_truth))) / sum(count(query))`.\n",
    "* **recall_per_item**: Similar to precision_per_item. How many segments in `ground_truth` overlap with *any* segment in `query`? `sum(count(overlap(query, ground_truth))) / sum(count(ground_truth))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:41:48.235431Z",
     "start_time": "2019-01-30T19:41:48.176490Z"
    }
   },
   "outputs": [],
   "source": [
    "# Returns precision, recall, precision_per_item, recall_per_item\n",
    "def compute_statistics(query_intrvllists, ground_truth_intrvllists):\n",
    "    total_query_time = 0\n",
    "    total_query_segments = 0\n",
    "    total_ground_truth_time = 0\n",
    "    total_ground_truth_segments = 0\n",
    "    \n",
    "    for video in query_intrvllists:\n",
    "        total_query_time += query_intrvllists[video].coalesce().get_total_time()\n",
    "        total_query_segments += query_intrvllists[video].size()\n",
    "    for video in ground_truth_intrvllists:\n",
    "        total_ground_truth_time += ground_truth_intrvllists[video].coalesce().get_total_time()\n",
    "        total_ground_truth_segments += ground_truth_intrvllists[video].size()\n",
    "        \n",
    "    total_overlap_time = 0\n",
    "    overlapping_query_segments = 0\n",
    "    overlapping_ground_truth_segments = 0\n",
    "    \n",
    "    for video in query_intrvllists:\n",
    "        if video in ground_truth_intrvllists:\n",
    "            query_list = query_intrvllists[video]\n",
    "            gt_list = ground_truth_intrvllists[video]\n",
    "            \n",
    "            total_overlap_time += query_list.overlaps(gt_list).coalesce().get_total_time()\n",
    "            overlapping_query_segments += query_list.filter_against(gt_list, predicate=overlaps()).size()\n",
    "            overlapping_ground_truth_segments += gt_list.filter_against(query_list, predicate=overlaps()).size()\n",
    "    \n",
    "    if total_query_time == 0:\n",
    "        precision = 1.0\n",
    "        precision_per_item = 1.0\n",
    "    else:\n",
    "        precision = total_overlap_time / total_query_time\n",
    "        precision_per_item = overlapping_query_segments / total_query_segments\n",
    "    \n",
    "    if total_ground_truth_time == 0:\n",
    "        recall = 1.0\n",
    "        recall_per_item = 1.0\n",
    "    else:\n",
    "        recall = total_overlap_time / total_ground_truth_time\n",
    "        recall_per_item = overlapping_ground_truth_segments / total_ground_truth_segments\n",
    "    \n",
    "    return precision, recall, precision_per_item, recall_per_item\n",
    "\n",
    "def print_statistics(query_intrvllists, ground_truth_intrvllists):\n",
    "    precision, recall, precision_per_item, recall_per_item = compute_statistics(\n",
    "        query_intrvllists, ground_truth_intrvllists)\n",
    "\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Precision Per Item: \", precision_per_item)\n",
    "    print(\"Recall Per Item: \", recall_per_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's just visualize all the labeled data. Interviews are in red, panels are in blue, and commercials are in purple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T06:56:22.377656Z",
     "start_time": "2019-01-10T06:56:18.681956Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interviews = LabeledInterview.objects \\\n",
    "        .annotate(fps=F('video__fps')) \\\n",
    "        .annotate(min_frame=F('fps') * F('start')) \\\n",
    "        .annotate(max_frame=F('fps') * F('end'))\n",
    "panels = LabeledPanel.objects \\\n",
    "        .annotate(fps=F('video__fps')) \\\n",
    "        .annotate(min_frame=F('fps') * F('start')) \\\n",
    "        .annotate(max_frame=F('fps') * F('end'))\n",
    "commercials = LabeledCommercial.objects \\\n",
    "        .annotate(fps=F('video__fps')) \\\n",
    "        .annotate(min_frame=F('fps') * F('start')) \\\n",
    "        .annotate(max_frame=F('fps') * F('end'))\n",
    "\n",
    "result = intrvllists_to_result(qs_to_intrvllists(interviews))\n",
    "add_intrvllists_to_result(result, qs_to_intrvllists(panels), color=\"blue\")\n",
    "add_intrvllists_to_result(result, qs_to_intrvllists(commercials), color=\"purple\")\n",
    "\n",
    "esper_widget(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interviews with Bernie Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T07:06:18.870211Z",
     "start_time": "2019-01-10T07:06:18.752183Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's get all interviews of Bernie Sanders in our dataset and display it as black.\n",
    "# For this task, we won't display any interviews that weren't original appearances.\n",
    "\n",
    "bernie_interviews = LabeledInterview.objects \\\n",
    "        .annotate(fps=F('video__fps')) \\\n",
    "        .annotate(min_frame=F('fps') * F('start')) \\\n",
    "        .annotate(max_frame=F('fps') * F('end')) \\\n",
    "        .filter(guest1=\"bernie sanders\")\n",
    "\n",
    "bernie_interviews_intrvllists = qs_to_intrvllists(bernie_interviews)\n",
    "bernie_interviews_original_intrvllists = qs_to_intrvllists(bernie_interviews.filter(original=True))\n",
    "\n",
    "# Hide result in a function for namespace reasons\n",
    "def get_result():\n",
    "    result = intrvllists_to_result(bernie_interviews_original_intrvllists, color='black')\n",
    "\n",
    "    return result\n",
    "\n",
    "esper_widget(get_result(), show_middle_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:08:54.839830Z",
     "start_time": "2018-11-05T18:08:54.808070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to get results with ground truth\n",
    "\n",
    "def result_with_ground_truth(intrvllists):\n",
    "    result = intrvllists_to_result(bernie_interviews_original_intrvllists, color='black')\n",
    "    add_intrvllists_to_result(result, intrvllists, color='red')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T19:49:33.778558Z",
     "start_time": "2019-01-11T19:49:13.889464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's query for Bernie Sanders interviews. This may take a while to materialize all the data.\n",
    "\n",
    "identities = FaceIdentity.objects.filter(face__shot__video_id__in=sandbox_videos)\n",
    "hosts = identities.filter(face__is_host=True)\n",
    "sanders = identities.filter(identity__name=\"bernie sanders\").filter(probability__gt=0.7)\n",
    "\n",
    "hosts_intrvllists = qs_to_intrvllists(hosts\n",
    "    .annotate(video_id=F(\"face__shot__video_id\"))\n",
    "    .annotate(min_frame=F(\"face__shot__min_frame\"))\n",
    "    .annotate(max_frame=F(\"face__shot__max_frame\")))\n",
    "sanders_intrvllists = qs_to_intrvllists(sanders\n",
    "    .annotate(video_id=F(\"face__shot__video_id\"))\n",
    "    .annotate(min_frame=F(\"face__shot__min_frame\"))\n",
    "    .annotate(max_frame=F(\"face__shot__max_frame\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:54.177915Z",
     "start_time": "2018-11-05T18:15:53.893391Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get all shots with Bernie Sanders and a host\n",
    "sanders_with_host_intrvllists = {}\n",
    "for video in sanders_intrvllists:\n",
    "    if video in hosts_intrvllists:\n",
    "        sanders_with_host_intrvllists[video] = sanders_intrvllists[video].overlaps(hosts_intrvllists[video]).coalesce()\n",
    "\n",
    "print_statistics(sanders_with_host_intrvllists, bernie_interviews_original_intrvllists)\n",
    "\n",
    "esper_widget(result_with_ground_truth(sanders_with_host_intrvllists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T23:43:14.593160Z",
     "start_time": "2018-10-30T23:43:14.561056Z"
    }
   },
   "source": [
    "What do we get from those statistics? We are missing half the interviews, but we're hitting all of them. This tells us that part of our problem has to do with not coalescing well enough. We also have a problem where half our query segments do *not* hit an interview, so we need to cull some. Let's try something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:54.362600Z",
     "start_time": "2018-11-05T18:15:54.181445Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We're going to look for the following patterns:\n",
    "    (Bernie Sanders + host) -> host OR\n",
    "    host -> (Bernie Sanders + host) OR\n",
    "    (Bernie Sanders + host) -> Bernie Sanders OR\n",
    "    Bernie Sanders -> (Bernie Sanders + host)\n",
    "\n",
    "We'll coalesce that, and then check in with the Esper widget again.\n",
    "'''\n",
    "sanders_interview_intrvllists = {}\n",
    "for video in sanders_with_host_intrvllists:\n",
    "    sanders_with_host = sanders_with_host_intrvllists[video]\n",
    "    hosts = hosts_intrvllists[video]\n",
    "    sanders = sanders_intrvllists[video]\n",
    "    \n",
    "    sanders_interview_intrvllists[video] = sanders_with_host.merge(\n",
    "        hosts, predicate=or_pred(before(max_dist=10), after(max_dist=10))).set_union(\n",
    "        sanders_with_host.merge(sanders, predicate=or_pred(before(max_dist=10), after(max_dist=10)))\n",
    "    ).coalesce()\n",
    "\n",
    "print_statistics(sanders_interview_intrvllists, bernie_interviews_original_intrvllists)\n",
    "\n",
    "esper_widget(result_with_ground_truth(sanders_interview_intrvllists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're much closer to getting all the interviews, but we still have some large gaps. Let's try to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:54.613085Z",
     "start_time": "2018-11-05T18:15:54.365505Z"
    }
   },
   "outputs": [],
   "source": [
    "investigation_result = intrvllists_to_result(bernie_interviews_original_intrvllists, color='black')\n",
    "add_intrvllists_to_result(investigation_result, sanders_with_host_intrvllists, color='orange')\n",
    "add_intrvllists_to_result(investigation_result, sanders_intrvllists, color='blue')\n",
    "add_intrvllists_to_result(investigation_result, sanders_interview_intrvllists, color='red')\n",
    "\n",
    "esper_widget(investigation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some gaps because of consecutive Bernie Sanders or host shots. Let's dilate and coalesce those and have another go at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:54.800421Z",
     "start_time": "2018-11-05T18:15:54.615645Z"
    }
   },
   "outputs": [],
   "source": [
    "sanders_interview_consec_intrvllists = {}\n",
    "for video in sanders_with_host_intrvllists:\n",
    "    sanders_with_host = sanders_with_host_intrvllists[video]\n",
    "    hosts = hosts_intrvllists[video].dilate(10).coalesce().dilate(-10)\n",
    "    sanders = sanders_intrvllists[video].dilate(10).coalesce().dilate(-10)\n",
    "    \n",
    "    sanders_interview_consec_intrvllists[video] = sanders_with_host.merge(\n",
    "        hosts, predicate=or_pred(or_pred(overlaps(), before(max_dist=10)), after(max_dist=10))).set_union(\n",
    "        sanders_with_host.merge(sanders, predicate=or_pred(or_pred(overlaps(), before(max_dist=10)), after(max_dist=10)))\n",
    "    ).coalesce()\n",
    "\n",
    "print_statistics(sanders_interview_consec_intrvllists, bernie_interviews_original_intrvllists)\n",
    "\n",
    "esper_widget(result_with_ground_truth(sanders_interview_consec_intrvllists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:54.914999Z",
     "start_time": "2018-11-05T18:15:54.803321Z"
    }
   },
   "outputs": [],
   "source": [
    "sanders_interview_filtered_intrvllists = {}\n",
    "for video in sanders_interview_intrvllists:\n",
    "    sanders_interview = sanders_interview_consec_intrvllists[video]\n",
    "    \n",
    "    sanders_interview_filtered_intrvllists[video] = sanders_interview \\\n",
    "        .dilate(600) \\\n",
    "        .coalesce() \\\n",
    "        .dilate(-600) \\\n",
    "        .filter_length(min_length=1350)\n",
    "\n",
    "print_statistics(sanders_interview_filtered_intrvllists, bernie_interviews_original_intrvllists)\n",
    "\n",
    "esper_widget(result_with_ground_truth(sanders_interview_filtered_intrvllists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good. We still have some false positives, but it's hard to get rid of those with what we have right now. Let's summarize what we did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:15:56.286532Z",
     "start_time": "2018-11-05T18:15:54.917790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show multiple stages of our query process all in one timeline.\n",
    "summarize_bernie_result = intrvllists_to_result(bernie_interviews_original_intrvllists, color='black')\n",
    "add_intrvllists_to_result(summarize_bernie_result, sanders_with_host_intrvllists, color='orange')\n",
    "add_intrvllists_to_result(summarize_bernie_result, sanders_intrvllists, color='blue')\n",
    "add_intrvllists_to_result(summarize_bernie_result, hosts_intrvllists, color='purple')\n",
    "add_intrvllists_to_result(summarize_bernie_result, sanders_interview_intrvllists, color='green')\n",
    "add_intrvllists_to_result(summarize_bernie_result, sanders_interview_consec_intrvllists, color='brown')\n",
    "add_intrvllists_to_result(summarize_bernie_result, sanders_interview_filtered_intrvllists, color='red')\n",
    "\n",
    "esper_widget(summarize_bernie_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interviews with Kellyanne Conway and John McCain\n",
    "\n",
    "Now that we have a simple query for interviews with Bernie Sanders, let's do the same thing for Kellyanne Conway and John McCain, using our best method from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T18:43:31.639953Z",
     "start_time": "2019-01-14T18:43:31.589603Z"
    }
   },
   "outputs": [],
   "source": [
    "# ground truth for interviews where guest 1 is X\n",
    "def ground_truth_interviews_intrvllists(name, original=True):\n",
    "    interviews = LabeledInterview.objects \\\n",
    "        .annotate(fps=F('video__fps')) \\\n",
    "        .annotate(min_frame=F('fps') * F('start')) \\\n",
    "        .annotate(max_frame=F('fps') * F('end')) \\\n",
    "        .filter(guest1=name)\n",
    "    if original:\n",
    "        interviews = interviews.filter(original=original)\n",
    "    return qs_to_intrvllists(interviews)\n",
    "\n",
    "# intrvllists for shots with a face with identity X\n",
    "def named_person_intrvllists(name):\n",
    "    identities = FaceIdentity.objects.filter(face__shot__video_id__in=sandbox_videos)\n",
    "    person = identities.filter(identity__name=name).filter(probability__gt=0.7)\n",
    "    \n",
    "    return qs_to_intrvllists(person\n",
    "        .annotate(video_id=F(\"face__shot__video_id\"))\n",
    "        .annotate(min_frame=F(\"face__shot__min_frame\"))\n",
    "        .annotate(max_frame=F(\"face__shot__max_frame\")))\n",
    "\n",
    "# helper function to get hosts\n",
    "def host_intrvllists():\n",
    "    host = identities.filter(face__is_host=True)\n",
    "\n",
    "    return qs_to_intrvllists(hosts\n",
    "        .annotate(video_id=F(\"face__shot__video_id\"))\n",
    "        .annotate(min_frame=F(\"face__shot__min_frame\"))\n",
    "        .annotate(max_frame=F(\"face__shot__max_frame\")))\n",
    "\n",
    "# query for interviews of person X\n",
    "def interview_query(person_intrvllists, host_intrvllists):\n",
    "    interview_intrvllists = {}\n",
    "    for video in person_intrvllists:\n",
    "        if video not in host_intrvllists:\n",
    "            continue\n",
    "        person = person_intrvllists[video]\n",
    "        host = host_intrvllists[video]\n",
    "        person_with_host = person.overlaps(host).coalesce()\n",
    "        \n",
    "        overlaps_before_or_after_pred = or_pred(or_pred(\n",
    "            overlaps(), before(max_dist=10)), after(max_dist=10))\n",
    "        \n",
    "        interview_candidates = person_with_host \\\n",
    "            .merge(host, predicate=overlaps_before_or_after_pred) \\\n",
    "            .set_union(person_with_host.merge(\n",
    "                person, predicate=overlaps_before_or_after_pred)) \\\n",
    "            .coalesce()\n",
    "        \n",
    "        interviews_filtered = interview_candidates \\\n",
    "            .dilate(600) \\\n",
    "            .coalesce() \\\n",
    "            .dilate(-600) \\\n",
    "            .filter_length(min_length=1350)\n",
    "        \n",
    "        if interviews_filtered.size() > 0:\n",
    "            interview_intrvllists[video] = interviews_filtered\n",
    "    \n",
    "    return interview_intrvllists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T19:48:31.331552Z",
     "start_time": "2019-01-11T19:48:31.304116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to do all the above in one call\n",
    "\n",
    "def summarize_named_interview(name, original=True):\n",
    "    gt = ground_truth_interviews_intrvllists(name, original)\n",
    "    person = named_person_intrvllists(name)\n",
    "    person_interviews = interview_query(person, hosts_intrvllists)\n",
    "\n",
    "    print_statistics(person_interviews, gt)\n",
    "\n",
    "    summarize_result = intrvllists_to_result(gt, color='black')\n",
    "    add_intrvllists_to_result(summarize_result, person, color='blue')\n",
    "    add_intrvllists_to_result(summarize_result, hosts_intrvllists, color='purple')\n",
    "    add_intrvllists_to_result(summarize_result, person_interviews, color='red')\n",
    "\n",
    "    return summarize_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T19:53:02.703348Z",
     "start_time": "2019-01-11T19:53:00.750218Z"
    }
   },
   "outputs": [],
   "source": [
    "# This will take a while to materialize some of the data\n",
    "\n",
    "kellyanne_result = summarize_named_interview(\"kellyanne conway\")\n",
    "esper_widget(kellyanne_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T18:16:55.853296Z",
     "start_time": "2018-11-05T18:16:23.483193Z"
    }
   },
   "outputs": [],
   "source": [
    "# This will take a while to materialize some of the data\n",
    "\n",
    "mccain_result = summarize_named_interview(\"john mccain\")\n",
    "esper_widget(mccain_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in summary, the precision for Kellyanne Conway is pretty good (95%), but it's not as good for John McCain. The main reason is that there are very few interviews of John McCain, so any false positives (there is one) throw the precision numbers quite off. There's also a big false negative for John McCain - an interview with Jake Tapper that was played verbatim on CNN, but not on Jake Tapper's show. This false negative occurs because Jake Tapper's face wasn't registered as a host during that playtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify after detecting fixed stride faces and new identity labeling model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:41:17.755503Z",
     "start_time": "2019-01-30T19:41:02.483600Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from esper.interview import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:44:17.936667Z",
     "start_time": "2019-01-30T19:44:17.883717Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_interview(person_name):\n",
    "    if person_name == 'donald trump':\n",
    "        gt = pickle.load(open('/app/data/interview_gt.pkl', 'rb'))\n",
    "        gt = VideoIntervalCollection({id: IntervalList(list) for id, list in gt.items()})\n",
    "        gt = intrvlcol_second2frame(gt)\n",
    "    else:\n",
    "        gt = ground_truth_interviews(person_name)\n",
    "    \n",
    "    video_ids=list(gt.get_allintervals().keys())\n",
    "#     print(video_ids)\n",
    "\n",
    "    host_list = [h.name for s in CanonicalShow.objects.all() for h in s.hosts.all() ]\n",
    "    host_list = list(set(host_list))\n",
    "    \n",
    "    person_intrvlcol, host_intrvlcol, commercial = load_intervals(video_ids, person_name, host_list)\n",
    "#     return person_intrvlcol, host_intrvlcol, commercial, gt\n",
    "    \n",
    "    interviews, person_only, host_only, person_with_host = interview_query(person_intrvlcol, host_intrvlcol, commercial)\n",
    "#     return interviews, person_in_interviews\n",
    "    \n",
    "    print(\"Total length: %.1fh\" % (count_duration(intrvlcol_frame2second(gt)) / 3600))\n",
    "    print_statistics(intrvlcol_second2frame(interviews).get_allintervals(), gt.get_allintervals())\n",
    "\n",
    "    summarize_result = intrvllists_to_result(gt.get_allintervals(), color='green')\n",
    "    add_intrvllists_to_result(summarize_result, intrvlcol_second2frame(commercial).get_allintervals(), color='gray')\n",
    "    add_intrvllists_to_result(summarize_result, intrvlcol_second2frame(person_intrvlcol).get_allintervals(), color='blue')\n",
    "    add_intrvllists_to_result(summarize_result, intrvlcol_second2frame(host_intrvlcol).get_allintervals(), color='purple')\n",
    "    add_intrvllists_to_result(summarize_result, intrvlcol_second2frame(person_with_host).get_allintervals(), color='orange')\n",
    "    add_intrvllists_to_result(summarize_result, intrvlcol_second2frame(interviews).get_allintervals(), color='red')\n",
    "    return summarize_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-30T19:36:29.802Z"
    }
   },
   "outputs": [],
   "source": [
    "summarize_result_b = test_interview('bernie sanders')\n",
    "# esper_widget(summarize_result_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total: 3.5h\n",
    "Precision:  0.9171231330081376  \n",
    "Recall:  0.9754783719638195  \n",
    "Precision Per Item:  1.0  \n",
    "Recall Per Item:  0.8666666666666667  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T01:51:11.514001Z",
     "start_time": "2019-01-13T01:51:08.310745Z"
    }
   },
   "outputs": [],
   "source": [
    "summarize_result_k = test_interview('kellyanne conway')\n",
    "# esper_widget(summarize_result_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T23:19:40.333181Z",
     "start_time": "2019-01-12T23:19:40.148465Z"
    }
   },
   "source": [
    "Total: 2.2\n",
    "Precision:  0.9177643900547426  \n",
    "Recall:  0.890869917822613  \n",
    "Precision Per Item:  1.0  \n",
    "Recall Per Item:  0.75  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:44:21.302494Z",
     "start_time": "2019-01-30T19:44:19.972647Z"
    }
   },
   "outputs": [],
   "source": [
    "summarize_result_j = test_interview('john mccain')\n",
    "# esper_widget(summarize_result_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total: 0.9\n",
    "Precision:  0.8590926781804915  \n",
    "Recall:  0.9953915876457966  \n",
    "Precision Per Item:  1.0  \n",
    "Recall Per Item:  0.875  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's try to detect interviews in the whole dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T18:44:14.252954Z",
     "start_time": "2019-01-14T18:43:56.298875Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.interview import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect all the interviews with 2016 presidential candidates from 2015 to 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T19:49:08.756460Z",
     "start_time": "2019-01-13T19:49:08.726847Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2016 presidential candidates\n",
    "guest_list = ['Barack Obama', 'Donald Trump', 'Ted Cruz', 'John Kasich', 'Marco Rubio', 'Ben Carson', 'Jeb Bush',\n",
    "'Jim Gilmore', 'Chris Christie', 'Carly Fiorina', 'Rick Santorum', 'Rand Paul', 'Mike Huckabee',\n",
    "'Hillary Clinton', 'Bernie Sanders', 'Lincoln Chafee', 'Martin O’Malley', 'Jim Webb',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T01:04:37.799434Z",
     "start_time": "2019-01-12T01:04:37.112806Z"
    }
   },
   "outputs": [],
   "source": [
    "# get host list from canonical shows\n",
    "canonical_show_list = [s.name for s in CanonicalShow.objects.all()]\n",
    "host_list = [h.name for s in CanonicalShow.objects.all() for h in s.hosts.all() ]\n",
    "host_list = list(set(host_list))\n",
    "len(host_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T01:26:45.245715Z",
     "start_time": "2019-01-12T01:26:44.653063Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get video list\n",
    "videos = Video.objects.filter(time__year=2015, duplicate=False, corrupted=False,\n",
    "                             show__name__in=canonical_show_list)\n",
    "video_ids = [video.id for video in videos]\n",
    "len(video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all host and commercial\n",
    "host_intrvlcol = get_person_intrvlcol(host_list, video_ids=video_ids, face_size=0.2, \\\n",
    "                                          stride_face=False, probability=0.7, granularity='second')\n",
    "commercial = get_commercial_intrvlcol(video_ids, granularity='second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person_name in guest_list:\n",
    "    print('Searching interviews for {} ...'.format(person_name))\n",
    "    person_intrvlcol = get_person_intrvlcol(person_name, video_ids=video_ids, face_size=0.2, \n",
    "                                            stride_face=False, probability=0.7, granularity='second')\n",
    "    \n",
    "    interviews, person_in_interviews = interview_query(person_intrvlcol, host_intrvlcol, commercial)\n",
    "    save_interview(person_name, interviews, person_in_interviews)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect all the interviews with 40 important political figures in 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T01:05:14.047418Z",
     "start_time": "2019-01-31T01:05:13.903082Z"
    }
   },
   "outputs": [],
   "source": [
    "# political figures\n",
    "guest_list = ['Barack Obama', 'Donald Trump', 'Ted Cruz', 'John Kasich', 'Marco Rubio', 'Ben Carson', 'Jeb Bush',\n",
    "'Jim Gilmore', 'Chris Christie', 'Carly Fiorina', 'Rick Santorum', 'Rand Paul', 'Mike Huckabee',\n",
    "'Hillary Clinton', 'Bernie Sanders', 'Lincoln Chafee', 'Martin O’Malley', 'Jim Webb',\n",
    "\n",
    "'Sarah Palin', 'John Boehner', 'Paul Ryan', 'Newt Gingrich','Nancy Pelosi','Elizabeth Warren', 'Mitch McConnell',\n",
    "'Chuck Schumer','Harry Reid','Joe Biden', 'Kevin McCarthy', 'Steve Scalise', 'Bobby Jindal', 'John Cornyn',\n",
    "'Dick Durbin','Orrin Hatch', 'Lindsey Graham', 'Mitt Romney', 'Michelle Obama' ,'Bill Clinton', \n",
    "'George W Bush', 'Tim Kaine' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get host list from canonical shows\n",
    "canonical_show_list = [s.name for s in CanonicalShow.objects.all()]\n",
    "host_list = [h.name for s in CanonicalShow.objects.all() for h in s.hosts.all() ]\n",
    "host_list = list(set(host_list))\n",
    "len(host_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guest_ids = [Identity.objects.filter(name=name.lower())[0].id for name in guest_list]\n",
    "host_ids = [Identity.objects.filter(name=name.lower())[0].id for name in host_list]\n",
    "print(len(guest_ids), len(host_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all identity intervals precomputed using rust\n",
    "identity_dict = pickle.load(open('/app/data/identity_intervals_rust.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all host \n",
    "host_intrvllists = {}\n",
    "for host_id in host_ids:\n",
    "    if not host_id in identity_dict:\n",
    "        continue\n",
    "    print(host_id)\n",
    "    for video_id, values in identity_dict[host_id].items():\n",
    "        if not video_id in host_intrvllists:\n",
    "            host_intrvllists[video_id] = []\n",
    "        for stime, height in values:\n",
    "            host_intrvllists[video_id].append((stime, stime + 1./30, host_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilate each frame interval to the length of sample rate\n",
    "SAMPLE_RATE = 3\n",
    "cnt = 0\n",
    "for video_id, intervals in host_intrvllists.items():\n",
    "    host_intrvllists[video_id] = IntervalList(intervals).dilate(SAMPLE_RATE/2).coalesce().dilate(-SAMPLE_RATE/2)\n",
    "    cnt += 1\n",
    "    if cnt % 1000 == 0:\n",
    "        print(cnt)\n",
    "host_intrvlcol = VideoIntervalCollection(host_intrvllists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all commercial\n",
    "video_ids = host_intrvlcol.get_allintervals().keys()\n",
    "commercial = get_commercial_intrvlcol(video_ids, granularity='second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_person_intrvlcol_from_rust(person_id):\n",
    "    person_intrvlcol = {}\n",
    "    cnt = 0\n",
    "    for video_id, values in identity_dict[person_id].items():\n",
    "        intervals = []\n",
    "        for stime, height in values:\n",
    "            intervals.append((stime, stime+1./30, height))\n",
    "        person_intrvlcol[video_id] = IntervalList(intervals).dilate(SAMPLE_RATE/2).coalesce().dilate(-SAMPLE_RATE/2)\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "            print(cnt)\n",
    "    return VideoIntervalCollection(person_intrvlcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person_id, person_name in zip(guest_ids, guest_list):\n",
    "    print(person_id, person_name)\n",
    "    person_intrvlcol = get_person_intrvlcol_from_rust(person_id)\n",
    "    print(\"Get {} videos for {}\".format(len(person_intrvlcol.get_allintervals()), person_name))\n",
    "    \n",
    "    interviews, person_only, host_only, person_with_host = interview_query(person_intrvlcol, host_intrvlcol, commercial)\n",
    "    print(\"Get {} interview segments for {}\".format(count_intervals(interviews), person_name))\n",
    "    save_interview(person_name, '10y', interviews, person_only, host_only, person_with_host) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T04:33:06.278868Z",
     "start_time": "2019-01-12T04:31:47.192886Z"
    }
   },
   "source": [
    "## Visulaize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:50:12.443124Z",
     "start_time": "2019-01-30T19:50:08.751795Z"
    }
   },
   "outputs": [],
   "source": [
    "interviews, _, _, _ = load_interview(\"Newt Gingrich\", suffix='10y2')\n",
    "print(\"Num of videos %d, Num of intervals %d, Total length %.1fh\" %\n",
    "    (len(interviews.get_allintervals()), count_intervals(interviews), count_duration(interviews) / 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T05:14:28.795499Z",
     "start_time": "2019-01-14T05:14:27.378518Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "esper_widget(intrvllists_to_result(intrvlcol_second2frame(interviews).get_allintervals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze result stats (create csv for tablao) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T09:23:21.017917Z",
     "start_time": "2019-01-14T08:12:33.315233Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv = open('/app/result/interview/interview-10y-all-v2.csv', 'w')\n",
    "csv.write(','.join(['person_name', 'video_id', 'date', 'channel', 'host_name', 'host_ratio', 'host_rank'\\\n",
    "                    'interview_time', 'person_time', 'host_time', 'person_host_time']) + '\\n')\n",
    "\n",
    "ident_id_to_name = {x.id: x.name for x in Identity.objects.all()}\n",
    "channel_name_to_hosts = {}\n",
    "for v in Video.objects.all().distinct('show__canonical_show'):\n",
    "    canon_show = v.show.canonical_show\n",
    "    if v.channel.name not in channel_name_to_hosts:\n",
    "        channel_name_to_hosts[v.channel.name] = set()\n",
    "    channel_name_to_hosts[v.channel.name].update([h.name for h in canon_show.hosts.all()])\n",
    "labeler_ids = {l.id for l in Labeler.objects.filter(name__contains='face-identity-converted:')} | {l.id for l in Labeler.objects.filter(name__contains='face-identity:')}\n",
    "\n",
    "for person_name in guest_list:\n",
    "    print(person_name)\n",
    "    interview, person_only, host_only, person_with_host = load_interview(person_name, suffix='10y2')\n",
    "\n",
    "    for video_id in interview.get_allintervals():\n",
    "        video = Video.objects.filter(id=video_id)[0]\n",
    "        date = video.time.strftime('%Y-%m-%d')        \n",
    "        channel = video.channel.name\n",
    "        # get host from show name\n",
    "#         show = Show.objects.filter(name=video.show.canonical_show.name)[0]\n",
    "#         if len(show.hosts.all()) > 0:\n",
    "#             host_name = show.hosts.all()[0].name\n",
    "#         else:\n",
    "#             host_name = ''\n",
    "        \n",
    "        # get host by finding the most frequent person not X\n",
    "        ident_cnt = {}\n",
    "        for i in interview.get_intervallist(video_id).get_intervals():\n",
    "            idents = FaceIdentity.objects.filter(\n",
    "                face__frame__video_id=video_id,\n",
    "                face__frame__number__gte=i.start * video.fps, \n",
    "                face__frame__number__lte=i.end * video.fps,\n",
    "                probability__gt=0.8,\n",
    "                labeler__id__in=labeler_ids\n",
    "                )\n",
    "            for i in idents:\n",
    "                ident_name = i.identity.name\n",
    "                is_host = ident_name in channel_name_to_hosts[channel]\n",
    "                if is_host and ident_name != person_name.lower():\n",
    "                    if not ident_name in ident_cnt:\n",
    "                        ident_cnt[ident_name] = 0\n",
    "                    ident_cnt[ident_name] += 1\n",
    "#         print(ident_cnt)\n",
    "        ident_list = [(value, key) for key, value in ident_cnt.items()]\n",
    "        ident_list.sort()\n",
    "        ident_list = ident_list[::-1]\n",
    "        cnt_sum = sum([value for key, value in ident_cnt.items()])\n",
    "        ident_list = [(ident_name, 1.*cnt/cnt_sum) for (cnt, ident_name) in ident_list]\n",
    "#         print(ident_list)\n",
    "        \n",
    "        interview_time = count_duration(interview.get_intervallist(video_id))\n",
    "        person_time = count_duration(person_only.get_intervallist(video_id))\n",
    "        host_time = count_duration(host_only.get_intervallist(video_id))\n",
    "        person_host_time = count_duration(person_with_host.get_intervallist(video_id))\n",
    "        \n",
    "        for rank, (ident_name, ratio) in enumerate(ident_list):\n",
    "            if rank > 3 or ratio < 0.1:\n",
    "                continue\n",
    "            line = ','.join([person_name.lower(), str(video_id), date, channel, \\\n",
    "                             ident_name, str(ratio), str(rank), \\\n",
    "                            str(interview_time), str(person_time), str(host_time), str(person_host_time)]) + '\\n'\n",
    "            csv.write(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interview montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T23:50:02.715366Z",
     "start_time": "2019-01-13T23:49:50.770942Z"
    }
   },
   "outputs": [],
   "source": [
    "person_name = 'Ted Cruz'\n",
    "montage = montage_interview(person_name, suffix='final', width=2160, num_cols=10, target_height = 2160 // 10 * 9 // 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T23:50:02.843498Z",
     "start_time": "2019-01-13T23:50:02.718259Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.imshow(cv2.cvtColor(montage, cv2.COLOR_BGR2RGB))\n",
    "cv2.imwrite('/app/result/interview/{}-montage.jpg'.format(person_name), montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T09:04:01.965179Z",
     "start_time": "2019-01-13T09:02:37.156594Z"
    }
   },
   "outputs": [],
   "source": [
    "shotcut_interview(person_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interview validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create gt from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T01:41:16.658679Z",
     "start_time": "2019-01-13T01:41:15.740170Z"
    }
   },
   "outputs": [],
   "source": [
    "def time2second(time):\n",
    "    return time[0]*3600 + time[1]*60 + time[2]\n",
    "\n",
    "csv = open('/app/data/interview_groundtruth.csv', 'r')\n",
    "interview_gt = {}\n",
    "for line in csv:\n",
    "    columns = line[:-1].split(',')\n",
    "    video_path = columns[0].replace('tvnews_videos_', '')\n",
    "    video = Video.objects.filter(path__contains=video_path)[0]\n",
    "    \n",
    "    interview_gt[video.id] = []\n",
    "    for i in range(1, len(columns)):\n",
    "        if columns[i] == '':\n",
    "            continue\n",
    "        span = columns[i].split('-')\n",
    "        start = span[0].split(':')\n",
    "        end = span[1].split(':')\n",
    "        start = time2second((int(start[0]), int(start[1]), int(start[2])))\n",
    "        end = time2second((int(end[0]), int(end[1]), int(end[2])))\n",
    "        interview_gt[video.id].append((start, end, 0))\n",
    "interview_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T01:57:13.282989Z",
     "start_time": "2019-01-13T01:57:13.161767Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(interview_gt, open('/app/data/interview_gt.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate interview of person X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_gt = pickle.load(interview_gt, open('/app/data/interview_gt.pkl', 'wb')) # might need to separate for each person\n",
    "interviews, _, _, _ = load_interview(\"Newt Gingrich\", suffix='10y2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T01:44:42.560066Z",
     "start_time": "2019-01-13T01:44:42.527105Z"
    }
   },
   "outputs": [],
   "source": [
    "interview_intrvllists = {}\n",
    "gt_intrvllists = {}\n",
    "for video_id, values in interview_gt.items():\n",
    "    interview_intrvllists[video_id] = interviews.get_intervallist(video_id)\n",
    "    gt_intrvllists[video_id] = IntervalList(values)\n",
    "print_statistics(interview_intrvllists, gt_intrvllists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:55:37.668967Z",
     "start_time": "2019-01-30T19:55:37.635721Z"
    }
   },
   "source": [
    "## Pickle all computed interviews into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:02:02.978576Z",
     "start_time": "2019-01-14T06:01:57.649036Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interview_10y = {}\n",
    "for person_name in guest_list:\n",
    "    print(person_name)\n",
    "    path = '/app/result/interview/{}-interview-10y2.pkl'.format(person_name.lower())\n",
    "    interview_10y[person_name] = pickle.load(open(path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:02:38.498402Z",
     "start_time": "2019-01-14T06:02:38.002395Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(interview_10y, open('/app/result/interview/interview_10y-all.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
