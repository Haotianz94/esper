{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T05:21:28.422011Z",
     "start_time": "2019-03-11T05:21:22.422053Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "from datetime import timedelta, datetime\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "\n",
    "from esper.widget import *\n",
    "from esper.prelude import *\n",
    "from esper.spark_util import *\n",
    "from esper.validation import *\n",
    "from esper.plot_util import *\n",
    "from esper.spark_identity import get_screen_time_by_canonical_show_spark\n",
    "from esper.major_canonical_shows import MAJOR_CANONICAL_SHOWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T05:52:14.223322Z",
     "start_time": "2019-03-11T05:51:58.090329Z"
    }
   },
   "outputs": [],
   "source": [
    "black_faces = spark.load_csv('/app/data/black_face_ids.csv')\n",
    "black_faces = black_faces.withColumn('is_black', black_faces.score >= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T05:52:14.375148Z",
     "start_time": "2019-03-11T05:52:14.226184Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from datetime import tzinfo, timedelta, datetime, timezone\n",
    "import copy\n",
    "\n",
    "ZERO = timedelta(0)\n",
    "HOUR = timedelta(hours=1)\n",
    "SECOND = timedelta(seconds=1)\n",
    "\n",
    "# A class capturing the platform's idea of local time.\n",
    "# (May result in wrong values on historical times in\n",
    "#  timezones where UTC offset and/or the DST rules had\n",
    "#  changed in the past.)\n",
    "import time as _time\n",
    "\n",
    "STDOFFSET = timedelta(seconds = -_time.timezone)\n",
    "if _time.daylight:\n",
    "    DSTOFFSET = timedelta(seconds = -_time.altzone)\n",
    "else:\n",
    "    DSTOFFSET = STDOFFSET\n",
    "\n",
    "DSTDIFF = DSTOFFSET - STDOFFSET\n",
    "\n",
    "# A complete implementation of current DST rules for major US time zones.\n",
    "\n",
    "def first_sunday_on_or_after(dt):\n",
    "    days_to_go = 6 - dt.weekday()\n",
    "    if days_to_go:\n",
    "        dt += timedelta(days_to_go)\n",
    "    return dt\n",
    "\n",
    "\n",
    "# US DST Rules\n",
    "#\n",
    "# This is a simplified (i.e., wrong for a few cases) set of rules for US\n",
    "# DST start and end times. For a complete and up-to-date set of DST rules\n",
    "# and timezone definitions, visit the Olson Database (or try pytz):\n",
    "# http://www.twinsun.com/tz/tz-link.htm\n",
    "# http://sourceforge.net/projects/pytz/ (might not be up-to-date)\n",
    "#\n",
    "# In the US, since 2007, DST starts at 2am (standard time) on the second\n",
    "# Sunday in March, which is the first Sunday on or after Mar 8.\n",
    "DSTSTART_2007 = datetime(1, 3, 8, 2)\n",
    "# and ends at 2am (DST time) on the first Sunday of Nov.\n",
    "DSTEND_2007 = datetime(1, 11, 1, 2)\n",
    "# From 1987 to 2006, DST used to start at 2am (standard time) on the first\n",
    "# Sunday in April and to end at 2am (DST time) on the last\n",
    "# Sunday of October, which is the first Sunday on or after Oct 25.\n",
    "DSTSTART_1987_2006 = datetime(1, 4, 1, 2)\n",
    "DSTEND_1987_2006 = datetime(1, 10, 25, 2)\n",
    "# From 1967 to 1986, DST used to start at 2am (standard time) on the last\n",
    "# Sunday in April (the one on or after April 24) and to end at 2am (DST time)\n",
    "# on the last Sunday of October, which is the first Sunday\n",
    "# on or after Oct 25.\n",
    "DSTSTART_1967_1986 = datetime(1, 4, 24, 2)\n",
    "DSTEND_1967_1986 = DSTEND_1987_2006\n",
    "\n",
    "def us_dst_range(year):\n",
    "    # Find start and end times for US DST. For years before 1967, return\n",
    "    # start = end for no DST.\n",
    "    if 2006 < year:\n",
    "        dststart, dstend = DSTSTART_2007, DSTEND_2007\n",
    "    elif 1986 < year < 2007:\n",
    "        dststart, dstend = DSTSTART_1987_2006, DSTEND_1987_2006\n",
    "    elif 1966 < year < 1987:\n",
    "        dststart, dstend = DSTSTART_1967_1986, DSTEND_1967_1986\n",
    "    else:\n",
    "        return (datetime(year, 1, 1), ) * 2\n",
    "\n",
    "    start = first_sunday_on_or_after(dststart.replace(year=year))\n",
    "    end = first_sunday_on_or_after(dstend.replace(year=year))\n",
    "    return start, end\n",
    "\n",
    "\n",
    "class USTimeZone(tzinfo):\n",
    "\n",
    "    def __init__(self, hours, reprname, stdname, dstname):\n",
    "        self.stdoffset = timedelta(hours=hours)\n",
    "        self.reprname = reprname\n",
    "        self.stdname = stdname\n",
    "        self.dstname = dstname\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.reprname\n",
    "\n",
    "    def tzname(self, dt):\n",
    "        if self.dst(dt):\n",
    "            return self.dstname\n",
    "        else:\n",
    "            return self.stdname\n",
    "\n",
    "    def utcoffset(self, dt):\n",
    "        return self.stdoffset + self.dst(dt)\n",
    "\n",
    "    def dst(self, dt):\n",
    "        if dt is None or dt.tzinfo is None:\n",
    "            # An exception may be sensible here, in one or both cases.\n",
    "            # It depends on how you want to treat them.  The default\n",
    "            # fromutc() implementation (called by the default astimezone()\n",
    "            # implementation) passes a datetime with dt.tzinfo is self.\n",
    "            return ZERO\n",
    "        assert dt.tzinfo is self\n",
    "        start, end = us_dst_range(dt.year)\n",
    "        # Can't compare naive to aware objects, so strip the timezone from\n",
    "        # dt first.\n",
    "        dt = dt.replace(tzinfo=None)\n",
    "        if start + HOUR <= dt < end - HOUR:\n",
    "            # DST is in effect.\n",
    "            return HOUR\n",
    "        if end - HOUR <= dt < end:\n",
    "            # Fold (an ambiguous hour): use dt.fold to disambiguate.\n",
    "            return ZERO if dt.fold else HOUR\n",
    "        if start <= dt < start + HOUR:\n",
    "            # Gap (a non-existent hour): reverse the fold rule.\n",
    "            return HOUR if dt.fold else ZERO\n",
    "        # DST is off.\n",
    "        return ZERO\n",
    "\n",
    "    def fromutc(self, dt):\n",
    "        assert dt.tzinfo is self\n",
    "        start, end = us_dst_range(dt.year)\n",
    "        start = start.replace(tzinfo=self)\n",
    "        end = end.replace(tzinfo=self)\n",
    "        std_time = dt + self.stdoffset\n",
    "        dst_time = std_time + HOUR\n",
    "        if end <= dst_time < end + HOUR:\n",
    "            # Repeated hour\n",
    "            new_time = copy.copy(std_time)\n",
    "            return new_time #std_time.replace(fold=1)\n",
    "        if std_time < start or dst_time >= end:\n",
    "            # Standard time\n",
    "            return std_time\n",
    "        if start <= std_time < end - HOUR:\n",
    "            # Daylight saving time\n",
    "            return dst_time\n",
    "\n",
    "\n",
    "Eastern  = USTimeZone(-5, \"Eastern\",  \"EST\", \"EDT\")\n",
    "Central  = USTimeZone(-6, \"Central\",  \"CST\", \"CDT\")\n",
    "Mountain = USTimeZone(-7, \"Mountain\", \"MST\", \"MDT\")\n",
    "Pacific  = USTimeZone(-8, \"Pacific\",  \"PST\", \"PDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T05:52:22.149830Z",
     "start_time": "2019-03-11T05:52:14.377290Z"
    }
   },
   "outputs": [],
   "source": [
    "channel_id_to_name = {c.id: c.name for c in Channel.objects.all()}\n",
    "cshow_id_to_name = {c.id: c.name for c in CanonicalShow.objects.all()}\n",
    "video_id_to_path = {v.id: v.path for v in Video.objects.all()}\n",
    "# color_id_to_name = {c.id: c.name for c in HairColorName.objects.all()}\n",
    "color_id_to_name = {1: 'blond', 2: 'dark', 3: 'white', 4: 'dark', 5: 'dark', 6: ''}\n",
    "length_id_to_name = {c.id: c.name for c in HairLengthName.objects.all()}\n",
    "clothing_id_to_name = {c.id: c.name for c in ClothingName.objects.all()}\n",
    "gender_id_to_name = {g.id: g.name for g in Gender.objects.all()}\n",
    "\n",
    "channel_id_to_host_ids = defaultdict(set)\n",
    "for v in Video.objects.distinct('show__canonical_show'):\n",
    "    channel_id_to_host_ids[v.channel.id].update([\n",
    "        h.name for h in v.show.canonical_show.hosts.all()\n",
    "    ])\n",
    "\n",
    "def get_identity_is_host(channel_id, ident_name):\n",
    "    assert channel_id in channel_id_to_host_ids\n",
    "    return ident_name in channel_id_to_host_ids[channel_id]\n",
    "\n",
    "def get_date_hour_from_path(t):\n",
    "    tokens = t.split('_')\n",
    "    yyyymmdd = tokens[1]\n",
    "    hhmmss = tokens[2]\n",
    "    gmt = datetime(int(yyyymmdd[:4]), int(yyyymmdd[4:6]), int(yyyymmdd[6:]), \\\n",
    "                           int(hhmmss[:2]), tzinfo=timezone.utc)\n",
    "    est = gmt.astimezone(Eastern)\n",
    "    date = '{:04}-{:02}-{:02}'.format(est.year, est.month, est.day)\n",
    "    hour = est.hour\n",
    "    return date, hour\n",
    "\n",
    "def get_isoweekday(date):\n",
    "    dt = datetime.strptime(date, '%Y-%m-%d')\n",
    "    return dt.isoweekday()\n",
    "\n",
    "def get_height_udf(sat, max_val=100):\n",
    "    def height_udf(h):\n",
    "        return h if h < sat else max_val\n",
    "    return func.udf(height_udf, IntegerType())\n",
    "\n",
    "assert get_isoweekday('2018-09-07') == 5\n",
    "assert get_date_hour_from_path('tvnews/videos/MSNBCW_20190109_020000_Hardball_With_Chris_Matthews.mp4') == ('2019-01-08', 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:12:07.024696Z",
     "start_time": "2019-03-11T06:06:50.117493Z"
    }
   },
   "outputs": [],
   "source": [
    "face_genders = get_face_genders()\n",
    "face_genders = face_genders.where(\n",
    "    face_genders.labeler_id == Labeler.objects.get(name='knn-gender').id)\n",
    "      \n",
    "face_genders = face_genders.withColumn('is_host2', face_genders.host_probability > 0.5)\n",
    "face_genders = face_genders.withColumn('height_gte20', face_genders.height >= 0.2)\n",
    "\n",
    "face_genders = face_genders.join(\n",
    "    black_faces, black_faces.face_id == face_genders.face_id, 'left_outer'\n",
    ").select(\n",
    "    *[c if c != 'face_id' else 'face_genders.face_id' for c in face_genders.columns], \n",
    "    black_faces.is_black\n",
    ")\n",
    "face_genders = face_genders.na.fill({'is_black': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Gender Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T22:49:25.161230Z",
     "start_time": "2019-01-08T22:31:01.451740Z"
    }
   },
   "outputs": [],
   "source": [
    "# face_genders_nh = face_genders.where(face_genders.host_probability < 0.5)\n",
    "# screen_time_male, screen_time_female = OrderedDict(), OrderedDict()\n",
    "# screen_time_nh_male, screen_time_nh_female = OrderedDict(), OrderedDict()\n",
    "\n",
    "# print('Computing screen time across all channels')\n",
    "# screen_time_male['All Channels'] = sum_over_column(\n",
    "#     face_genders, 'duration', probability_column='male_probability'\n",
    "# )\n",
    "# screen_time_female['All Channels'] = sum_over_column(\n",
    "#     face_genders, 'duration', probability_column='female_probability'\n",
    "# )\n",
    "\n",
    "# print('Computing screen time across all channels (non-hosts)')\n",
    "# screen_time_nh_male['All Channels'] = sum_over_column(\n",
    "#     face_genders_nh, 'duration', probability_column='male_probability'\n",
    "# )\n",
    "# screen_time_nh_female['All Channels'] = sum_over_column(\n",
    "#     face_genders_nh, 'duration', probability_column='female_probability'\n",
    "# )\n",
    "\n",
    "# print('Computing screen time by channel')\n",
    "# channel_id_map = {c.id : c.name for c in Channel.objects.all()}\n",
    "# for k, v in sum_over_column(face_genders, 'duration', ['channel_id'], \n",
    "#                             probability_column='male_probability').items():\n",
    "#     screen_time_male[channel_id_map[k[0]]] = v\n",
    "# for k, v in sum_over_column(face_genders, 'duration', ['channel_id'], \n",
    "#                             probability_column='female_probability').items():\n",
    "#     screen_time_female[channel_id_map[k[0]]] = v\n",
    "    \n",
    "# print('Computing screen time by channel (non-host)')\n",
    "# for k, v in sum_over_column(face_genders_nh, 'duration', ['channel_id'], \n",
    "#                             probability_column='male_probability').items():\n",
    "#     screen_time_nh_male[channel_id_map[k[0]]] = v\n",
    "# for k, v in sum_over_column(face_genders_nh, 'duration', ['channel_id'], \n",
    "#                             probability_column='female_probability').items():\n",
    "#     screen_time_nh_female[channel_id_map[k[0]]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T06:27:46.529912Z",
     "start_time": "2019-01-03T06:27:33.050Z"
    }
   },
   "outputs": [],
   "source": [
    "# sort_order = ['All Channels'] + [c.name for c in Channel.objects.all().order_by('name')]\n",
    "# plot_binary_proportion_comparison(\n",
    "#     ['Male', 'Female'], [screen_time_male, screen_time_female],\n",
    "#     '', '', 'Proportion of Screen Time',\n",
    "#     raw_data_to_label_fn=None, figsize=(5,5), sort_order=sort_order,\n",
    "#     legend_loc=4,\n",
    "#     save_path='figures/gender-10y-screen-time.pdf'\n",
    "# )\n",
    "# plot_binary_proportion_comparison(\n",
    "#     ['Male', 'Female'], [screen_time_nh_male, screen_time_nh_female],\n",
    "#     '', '', 'Proportion of Screen Time (Excluding Hosts)',\n",
    "#     raw_data_to_label_fn=None, figsize=(5,5), sort_order=sort_order,\n",
    "#     legend_loc=4,\n",
    "#     save_path='figures/gender-10y-screen-time-no-host.pdf'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T22:53:08.328275Z",
     "start_time": "2019-01-08T22:49:25.164026Z"
    }
   },
   "outputs": [],
   "source": [
    "# canonical_show_map = {c.id : c.name for c in CanonicalShow.objects.all() if c.name in MAJOR_CANONICAL_SHOWS}\n",
    "# screen_time_male_by_show, screen_time_female_by_show = {}, {}\n",
    "# for k, v in sum_over_column(face_genders, 'duration', ['canonical_show_id'],\n",
    "#                             probability_column='male_probability').items():\n",
    "#     if k[0] in canonical_show_map:\n",
    "#         screen_time_male_by_show[canonical_show_map[k[0]]] = v\n",
    "# for k, v in sum_over_column(face_genders, 'duration', ['canonical_show_id'], \n",
    "#                             probability_column='female_probability').items():\n",
    "#     if k[0] in canonical_show_map:\n",
    "#         screen_time_female_by_show[canonical_show_map[k[0]]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T22:53:11.478792Z",
     "start_time": "2019-01-08T22:53:08.330108Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot_binary_proportion_comparison(\n",
    "#     ['Male', 'Female'], [screen_time_male_by_show, screen_time_female_by_show],\n",
    "#     'Gender Distribution of Screen Time vs. Show', '', 'Proportion of Screen Time',\n",
    "#     raw_data_to_label_fn=None, legend_loc=4,\n",
    "#     baseline_series_names=[\n",
    "#         'Baseline Male (Entire Dataset)', \n",
    "#         'Baseline Female (Entire Dataset)'\n",
    "#     ],\n",
    "#     baseline_data=[\n",
    "#         screen_time_male['All Channels'][0],\n",
    "#         screen_time_female['All Channels'][0]\n",
    "#     ],\n",
    "#     save_path='figures/gender-10y-screen-time-by-show.pdf',\n",
    "#     figsize=(30, 10)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T23:06:17.806633Z",
     "start_time": "2019-01-08T22:53:11.481577Z"
    }
   },
   "outputs": [],
   "source": [
    "# screen_time_nh_male_by_show, screen_time_nh_female_by_show = {}, {}\n",
    "# for k, v in sum_over_column(face_genders_nh, 'duration', ['canonical_show_id'],\n",
    "#                             probability_column='male_probability').items():\n",
    "#     if k[0] in canonical_show_map:\n",
    "#         screen_time_nh_male_by_show[canonical_show_map[k[0]]] = v\n",
    "# for k, v in sum_over_column(face_genders_nh, 'duration', ['canonical_show_id'], \n",
    "#                             probability_column='female_probability').items():\n",
    "#     if k[0] in canonical_show_map:\n",
    "#         screen_time_nh_female_by_show[canonical_show_map[k[0]]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T23:06:20.877355Z",
     "start_time": "2019-01-08T23:06:17.809279Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot_binary_proportion_comparison(\n",
    "#     ['Male (Excl. Hosts)', 'Female (Excl. Hosts)'], [screen_time_nh_male_by_show, screen_time_nh_female_by_show],\n",
    "#     'Gender Distribution of Screen Time (Excluding Hosts) vs. Show', '', 'Proportion of Screen Time',\n",
    "#     tertiary_series_names=['Male (Incl. Hosts)', 'Female (Incl. Hosts)'],\n",
    "#     tertiary_data=[screen_time_male_by_show, screen_time_female_by_show],\n",
    "# #     baseline_data=[\n",
    "# #         screen_time_male['All Channels'][0],\n",
    "# #         screen_time_female['All Channels'][0]\n",
    "# #     ],\n",
    "# #     baseline_series_names=[\n",
    "# #         'Baseline Male (Entire Dataset)', \n",
    "# #         'Baseline Female (Entire Dataset)'\n",
    "# #     ],\n",
    "#     raw_data_to_label_fn=None, legend_loc=4,\n",
    "#     save_path='figures/gender-10y-screen-time-by-show-no-host.pdf',\n",
    "#     figsize=(30, 10)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Gender CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:37:26.837697Z",
     "start_time": "2019-03-11T06:18:10.461539Z"
    }
   },
   "outputs": [],
   "source": [
    "gender_group_keys = [\n",
    "    'video_id', \n",
    "    'channel_id', \n",
    "    'canonical_show_id', \n",
    "    'in_commercial', \n",
    "    'is_host2', \n",
    "    'height_gte20', \n",
    "    'haircolor_id', \n",
    "#     'clothing_id', \n",
    "#     'hairlength_id', \n",
    "    'is_black'\n",
    "]\n",
    "\n",
    "print('Summing over male faces')\n",
    "male_st = sum_over_column(\n",
    "    face_genders, 'duration', gender_group_keys,\n",
    "    probability_column='male_probability')\n",
    "\n",
    "print('Summing over female faces')\n",
    "female_st = sum_over_column(\n",
    "    face_genders, 'duration', gender_group_keys,\n",
    "    probability_column='female_probability')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:45:08.084650Z",
     "start_time": "2019-03-11T06:37:26.840870Z"
    }
   },
   "outputs": [],
   "source": [
    "gender_outfile = '/app/data/gender_10y.csv'\n",
    "\n",
    "with open(gender_outfile, 'w') as f:\n",
    "    f.write(','.join([\n",
    "        'gender', \n",
    "        'video_id',\n",
    "#         'video_path',\n",
    "        'channel',\n",
    "        'canonical_show',\n",
    "        'date',\n",
    "        'hour',\n",
    "        'isoweekday', \n",
    "        'in_commercial', \n",
    "        'is_host',\n",
    "        'height_gte20',\n",
    "        'hair_color',\n",
    "#         'hair_length',\n",
    "#         'clothing',\n",
    "        'is_black',\n",
    "        'screentime_seconds',\n",
    "        'variance_seconds_sq'\n",
    "    ]))\n",
    "    f.write('\\r\\n')\n",
    "    \n",
    "    def write_row(g, k, v):\n",
    "        (\n",
    "            video_id, \n",
    "            channel_id, \n",
    "            cshow_id, \n",
    "            in_comm, \n",
    "            is_host, \n",
    "            bbox_height, \n",
    "            color_id, \n",
    "#             clothing_id, \n",
    "#             length_id, \n",
    "            is_black\n",
    "        ) = k\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        week_day = get_isoweekday(date)\n",
    "        row = [\n",
    "            g,\n",
    "            str(video_id),\n",
    "            channel_id_to_name[channel_id], \n",
    "            cshow_id_to_name[cshow_id],\n",
    "            date,\n",
    "            str(hour),\n",
    "            str(week_day), \n",
    "            str(in_comm), \n",
    "            str(is_host),\n",
    "            str(bbox_height),\n",
    "            color_id_to_name.get(color_id, ''),\n",
    "#             length_id_to_name.get(length_id, ''),\n",
    "#             clothing_id_to_name.get(clothing_id, ''),\n",
    "            str(is_black),\n",
    "            str(v[0]),\n",
    "            str(v[1])\n",
    "        ]\n",
    "        f.write(','.join(row))\n",
    "        f.write('\\r\\n')\n",
    "\n",
    "    row_count = 0\n",
    "    total_rows = len(female_st) + len(male_st)\n",
    "    for k in male_st:\n",
    "        write_row('m', k, male_st[k])\n",
    "        row_count += 1\n",
    "        if row_count % 10000 == 0:\n",
    "            print('  {} / {}'.format(row_count, total_rows))\n",
    "\n",
    "    for k in female_st:\n",
    "        write_row('f', k, female_st[k])        \n",
    "        row_count += 1\n",
    "        if row_count % 10000 == 0:\n",
    "            print('  {} / {}'.format(row_count, total_rows))\n",
    "    \n",
    "    print('Wrote {} rows'.format(row_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T07:08:10.946820Z",
     "start_time": "2019-03-11T06:57:19.609737Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "face_idents = get_face_identities(include_name=True)\n",
    "face_genders_basic = spark.load('query_facegender')\n",
    "face_genders_basic = face_genders_basic.where(\n",
    "    face_genders_basic.labeler_id == Labeler.objects.get(name='knn-gender').id)\n",
    "face_idents = face_idents.join(\n",
    "    face_genders_basic.select('face_id', 'gender_id'), \n",
    "    face_idents.face_id == face_genders_basic.face_id, 'left_outer'\n",
    ").select(\n",
    "    *[c if c != 'face_id' else 'face_identities.face_id' for c in face_idents.columns], \n",
    "    face_genders_basic.gender_id\n",
    ")\n",
    "face_idents = face_idents.join(\n",
    "    black_faces, black_faces.face_id == face_idents.face_id, 'left_outer'\n",
    ").select(\n",
    "    *[c if c != 'face_id' else 'face_identities.face_id' for c in face_idents.columns], \n",
    "    black_faces.is_black\n",
    ")\n",
    "face_idents = face_idents.na.fill({'is_black': False})\n",
    "face_idents = face_idents.withColumn('height_gte20', face_idents.height >= 0.2)\n",
    "\n",
    "ident_group_keys = [\n",
    "    'name', \n",
    "    'video_id', \n",
    "    'channel_id', \n",
    "    'canonical_show_id', \n",
    "    'in_commercial', \n",
    "    'height_gte20',\n",
    "    'haircolor_id', \n",
    "#     'hairlength_id', \n",
    "#     'clothing_id', \n",
    "    'gender_id',\n",
    "    'is_black'\n",
    "]\n",
    "\n",
    "print('Summing over identities')\n",
    "ident_st = sum_over_column(\n",
    "    face_idents, 'duration', ident_group_keys,\n",
    "    probability_column='probability')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T07:09:04.012248Z",
     "start_time": "2019-03-11T07:08:10.951051Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Computing true genders')\n",
    "def ident_to_true_gender(ident_st):\n",
    "    ident_mf_diff = {}\n",
    "    for k in ident_st:\n",
    "        name = k[0]\n",
    "        gender = gender_id_to_name.get(k[-2], '')\n",
    "        if name not in ident_mf_diff:\n",
    "            ident_mf_diff[name] = 0.\n",
    "        if gender == 'M':\n",
    "            ident_mf_diff[name] += ident_st[k][0]\n",
    "        elif gender == 'F':\n",
    "            ident_mf_diff[name] -= ident_st[k][0]\n",
    "    return {k: 'M' if v >= 0 else 'F' for k, v in ident_mf_diff.items()}\n",
    "name_to_true_gender = ident_to_true_gender(ident_st)\n",
    "\n",
    "print('Computing true is_black')\n",
    "def ident_to_true_is_black(ident_st):\n",
    "    ident_is_black_diff = {}\n",
    "    for k in ident_st:\n",
    "        name = k[0]\n",
    "        is_black = k[-1]\n",
    "        if name not in ident_is_black_diff:\n",
    "            ident_is_black_diff[name] = 0.\n",
    "        if is_black:\n",
    "            ident_is_black_diff[name] += ident_st[k][0]\n",
    "        else:\n",
    "            ident_is_black_diff[name] -= ident_st[k][0]\n",
    "    return {k: v >= 0 for k, v in ident_is_black_diff.items()}\n",
    "name_to_true_is_black = ident_to_true_is_black(ident_st)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T07:14:39.800018Z",
     "start_time": "2019-03-11T07:09:04.014876Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ident_outfile = '/app/data/identity_10y.csv'\n",
    "\n",
    "with open(ident_outfile, 'w') as f:\n",
    "    f.write(','.join([\n",
    "        'name',\n",
    "        'video_id',\n",
    "#         'video_path',\n",
    "        'channel', \n",
    "        'canonical_show', \n",
    "        'date', \n",
    "        'hour',\n",
    "        'isoweekday', \n",
    "        'in_commercial',\n",
    "        'height_gte20',\n",
    "        'hair_color',\n",
    "#         'hair_length',\n",
    "#         'clothing',\n",
    "        'pred_gender',\n",
    "        'true_gender',\n",
    "        'pred_is_black',\n",
    "        'true_is_black',\n",
    "        'is_host',\n",
    "        'screentime_seconds', \n",
    "        'variance_seconds_sq'\n",
    "    ]))\n",
    "    f.write('\\r\\n')\n",
    "    \n",
    "    def write_row(k, v):\n",
    "        (\n",
    "            name, \n",
    "            video_id,\n",
    "            channel_id, \n",
    "            cshow_id, \n",
    "            in_comm, \n",
    "            bbox_height, \n",
    "            color_id, \n",
    "#             length_id, \n",
    "#             clothing_id, \n",
    "            gender_id,\n",
    "            is_black,\n",
    "        ) = k\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        week_day = get_isoweekday(date)\n",
    "        row = [\n",
    "            name,\n",
    "            str(video_id),\n",
    "            channel_id_to_name[channel_id], \n",
    "            cshow_id_to_name[cshow_id],\n",
    "            date, \n",
    "            str(hour),\n",
    "            str(week_day),\n",
    "            str(in_comm),\n",
    "            str(bbox_height),\n",
    "            color_id_to_name.get(color_id, ''),\n",
    "#             length_id_to_name.get(length_id, ''),\n",
    "#             clothing_id_to_name.get(clothing_id, ''),\n",
    "            gender_id_to_name.get(gender_id, ''),\n",
    "            name_to_true_gender.get(name, ''),\n",
    "            str(is_black),\n",
    "            str(name_to_true_is_black.get(name, '')),\n",
    "            str(get_identity_is_host(channel_id, name)),\n",
    "            str(v[0]),\n",
    "            str(v[1])\n",
    "        ]\n",
    "        f.write(','.join(row))\n",
    "        f.write('\\r\\n')\n",
    "    \n",
    "    row_count = 0\n",
    "    for k in ident_st:\n",
    "        write_row(k, ident_st[k])\n",
    "        row_count += 1\n",
    "        if row_count % 10000 == 0:\n",
    "            print('  {} / {}'.format(row_count, len(ident_st)))\n",
    "    \n",
    "    print('Wrote {} rows'.format(row_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T07:24:47.406062Z",
     "start_time": "2019-03-11T07:15:27.350230Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Computing video id to commercials')\n",
    "VIDEO_ID_TO_COMMERCIALS = defaultdict(list)\n",
    "for c in get_commercials().select('video_id', 'min_frame', 'max_frame').collect():\n",
    "    VIDEO_ID_TO_COMMERCIALS[c.video_id].append(\n",
    "        (c.min_frame, c.max_frame)\n",
    "    )\n",
    "    \n",
    "def _annotate_frame_in_commercial(df):\n",
    "    assert ('video_id' in df.columns)\n",
    "    assert ('number' in df.columns)\n",
    "    def in_commercial_helper(video_id, frame_no):\n",
    "        if video_id in VIDEO_ID_TO_COMMERCIALS:\n",
    "            for c_min, c_max in VIDEO_ID_TO_COMMERCIALS[video_id]:\n",
    "                if frame_no >= c_min and frame_no <= c_max:\n",
    "                    return True\n",
    "        return False\n",
    "    my_udf = func.udf(in_commercial_helper, BooleanType())\n",
    "    df = df.withColumn(\n",
    "        'in_commercial', my_udf('video_id', 'number')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "print('Computing frames with host')\n",
    "if True:\n",
    "    faces = get_faces()\n",
    "    frames_w_host_df = faces.where(\n",
    "        faces.host_probability > 0.5\n",
    "    ).select('frame_id').distinct()\n",
    "    spark.save('frames_w_host', frames_w_host_df)\n",
    "\n",
    "print('Computing frames to face count')\n",
    "if True:\n",
    "    frames_face_count_df = faces.groupBy(\n",
    "        'frame_id'\n",
    "    ).agg(\n",
    "        func.count(func.lit(1)).alias('face_count')\n",
    "    )\n",
    "    spark.save('frames_face_count', frames_face_count_df)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T07:25:34.379146Z",
     "start_time": "2019-03-11T07:24:47.409231Z"
    }
   },
   "outputs": [],
   "source": [
    "videos = get_videos()\n",
    "videos = videos.where((videos.duplicate == False) & (videos.corrupted == False))\n",
    "frames = get_frames()\n",
    "frames_with_host = spark.load('frames_w_host').withColumn('has_host', func.lit(True))\n",
    "frames_face_count = spark.load('frames_face_count')\n",
    "frames = frames.join(\n",
    "    videos, frames.video_id == videos.id\n",
    ").join(\n",
    "    frames_with_host, frames.id == frames_with_host.frame_id, 'left_outer'\n",
    ").join(\n",
    "    frames_face_count, frames.id == frames_face_count.frame_id, 'left_outer'\n",
    ").select(\n",
    "    'frames.*',\n",
    "    videos.channel_id,\n",
    "    videos.canonical_show_id,\n",
    "    frames_with_host.has_host,\n",
    "    frames_face_count.face_count\n",
    ").where(\n",
    "    ((videos.threeyears_dataset == True) & (frames.number % func.floor(videos.fps * 3) == 0)) | \\\n",
    "    ((videos.threeyears_dataset == False) & (frames.number % func.ceil(videos.fps * 3) == 0))\n",
    ")\n",
    "frames = _annotate_frame_in_commercial(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T07:31:22.382696Z",
     "start_time": "2019-03-11T07:25:34.381836Z"
    }
   },
   "outputs": [],
   "source": [
    "video_outfile = '/app/data/video_10y.csv'\n",
    "\n",
    "print('Summing over frames')\n",
    "with open(video_outfile, 'w') as f:\n",
    "    f.write(','.join([\n",
    "        'video_id',\n",
    "#         'video_path',\n",
    "        'channel', \n",
    "        'canonical_show', \n",
    "        'date', \n",
    "        'hour',\n",
    "        'isoweekday', \n",
    "        'in_commercial', \n",
    "        'host_onscreen',\n",
    "        'num_faces_onscreen',\n",
    "        'screentime_seconds'\n",
    "    ]))\n",
    "    f.write('\\r\\n')\n",
    "    \n",
    "    row_count = 0\n",
    "    for row in frames.groupBy(\n",
    "        'video_id', 'channel_id', 'canonical_show_id', 'in_commercial', 'has_host', 'face_count'\n",
    "    ).agg(\n",
    "        func.count(func.lit(1)).alias('frame_count')\n",
    "    ).sort(\n",
    "        'channel_id', 'canonical_show_id', 'video_id', 'in_commercial', 'has_host', 'face_count'\n",
    "    ).collect():\n",
    "        video_id = row.video_id\n",
    "        channel_id = row.channel_id\n",
    "        cshow_id = row.canonical_show_id\n",
    "        in_comm = row.in_commercial\n",
    "        has_host = row.has_host == True\n",
    "        face_count = row.face_count\n",
    "        if face_count is None:\n",
    "            face_count = 0\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        week_day = get_isoweekday(date)\n",
    "        f.write(','.join([\n",
    "            str(video_id),\n",
    "            channel_id_to_name[channel_id], \n",
    "            cshow_id_to_name[cshow_id],\n",
    "            date, \n",
    "            str(hour),\n",
    "            str(week_day),\n",
    "            str(in_comm), \n",
    "            str(has_host),\n",
    "            str(face_count),\n",
    "            str(row.frame_count * 3)\n",
    "        ]))\n",
    "        f.write('\\r\\n')\n",
    "        row_count += 1\n",
    "        if row_count % 10000 == 0:\n",
    "            print(row_count)\n",
    "    print('Wrote {} rows'.format(row_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T04:24:24.039813Z",
     "start_time": "2019-01-05T04:24:23.914518Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T05:46:33.664717Z",
     "start_time": "2019-03-11T05:22:13.219407Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
