{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T22:13:55.742942Z",
     "start_time": "2019-01-05T22:13:48.816537Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "from datetime import timedelta, datetime\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "\n",
    "from esper.widget import *\n",
    "from esper.prelude import *\n",
    "from esper.spark_util import *\n",
    "from esper.validation import *\n",
    "from esper.plot_util import *\n",
    "from esper.spark_identity import get_screen_time_by_canonical_show_spark\n",
    "from esper.major_canonical_shows import MAJOR_CANONICAL_SHOWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T22:28:05.290604Z",
     "start_time": "2019-01-05T22:13:55.746290Z"
    }
   },
   "outputs": [],
   "source": [
    "faces = get_faces()\n",
    "face_genders = get_face_genders()\n",
    "face_genders = face_genders.where(\n",
    "    face_genders.labeler_id == Labeler.objects.get(name='rudecarnie').id)\n",
    "      \n",
    "face_genders = face_genders.withColumn('is_host2', face_genders.host_probability > 0.5)\n",
    "face_genders = face_genders.withColumn(\n",
    "    'height2', func.ceil(face_genders.height * 100 / 10) * 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Gender Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T07:14:44.032075Z",
     "start_time": "2019-01-03T07:00:29.194699Z"
    }
   },
   "outputs": [],
   "source": [
    "face_genders_nh = face_genders.where(face_genders.host_probability < 0.5)\n",
    "screen_time_male, screen_time_female = OrderedDict(), OrderedDict()\n",
    "screen_time_nh_male, screen_time_nh_female = OrderedDict(), OrderedDict()\n",
    "\n",
    "print('Computing screen time across all channels')\n",
    "screen_time_male['All Channels'] = sum_over_column(\n",
    "    face_genders, 'duration', probability_column='male_probability'\n",
    ")\n",
    "screen_time_female['All Channels'] = sum_over_column(\n",
    "    face_genders, 'duration', probability_column='female_probability'\n",
    ")\n",
    "\n",
    "print('Computing screen time across all channels (non-hosts)')\n",
    "screen_time_nh_male['All Channels'] = sum_over_column(\n",
    "    face_genders_nh, 'duration', probability_column='male_probability'\n",
    ")\n",
    "screen_time_nh_female['All Channels'] = sum_over_column(\n",
    "    face_genders_nh, 'duration', probability_column='female_probability'\n",
    ")\n",
    "\n",
    "# print('Computing screen time by channel')\n",
    "# channel_id_map = {c.id : c.name for c in Channel.objects.all()}\n",
    "# for k, v in sum_over_column(face_genders, 'duration', ['channel_id'], \n",
    "#                             probability_column='male_probability').items():\n",
    "#     screen_time_male[channel_id_map[k[0]]] = v\n",
    "# for k, v in sum_over_column(face_genders, 'duration', ['channel_id'], \n",
    "#                             probability_column='female_probability').items():\n",
    "#     screen_time_female[channel_id_map[k[0]]] = v\n",
    "    \n",
    "# print('Computing screen time by channel (non-host)')\n",
    "# for k, v in sum_over_column(face_genders_nh, 'duration', ['channel_id'], \n",
    "#                             probability_column='male_probability').items():\n",
    "#     screen_time_nh_male[channel_id_map[k[0]]] = v\n",
    "# for k, v in sum_over_column(face_genders_nh, 'duration', ['channel_id'], \n",
    "#                             probability_column='female_probability').items():\n",
    "#     screen_time_nh_female[channel_id_map[k[0]]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T06:27:46.529912Z",
     "start_time": "2019-01-03T06:27:33.050Z"
    }
   },
   "outputs": [],
   "source": [
    "# sort_order = ['All Channels'] + [c.name for c in Channel.objects.all().order_by('name')]\n",
    "# plot_binary_proportion_comparison(\n",
    "#     ['Male', 'Female'], [screen_time_male, screen_time_female],\n",
    "#     '', '', 'Proportion of Screen Time',\n",
    "#     raw_data_to_label_fn=None, figsize=(5,5), sort_order=sort_order,\n",
    "#     legend_loc=4,\n",
    "#     save_path='figures/gender-10y-screen-time.pdf'\n",
    "# )\n",
    "# plot_binary_proportion_comparison(\n",
    "#     ['Male', 'Female'], [screen_time_nh_male, screen_time_nh_female],\n",
    "#     '', '', 'Proportion of Screen Time (Excluding Hosts)',\n",
    "#     raw_data_to_label_fn=None, figsize=(5,5), sort_order=sort_order,\n",
    "#     legend_loc=4,\n",
    "#     save_path='figures/gender-10y-screen-time-no-host.pdf'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T07:32:24.293266Z",
     "start_time": "2019-01-03T07:29:06.461537Z"
    }
   },
   "outputs": [],
   "source": [
    "canonical_show_map = {c.id : c.name for c in CanonicalShow.objects.all() if c.name in MAJOR_CANONICAL_SHOWS}\n",
    "screen_time_male_by_show, screen_time_female_by_show = {}, {}\n",
    "for k, v in sum_over_column(face_genders, 'duration', ['canonical_show_id'],\n",
    "                            probability_column='male_probability').items():\n",
    "    if k[0] in canonical_show_map:\n",
    "        screen_time_male_by_show[canonical_show_map[k[0]]] = v\n",
    "for k, v in sum_over_column(face_genders, 'duration', ['canonical_show_id'], \n",
    "                            probability_column='female_probability').items():\n",
    "    if k[0] in canonical_show_map:\n",
    "        screen_time_female_by_show[canonical_show_map[k[0]]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T07:32:27.958962Z",
     "start_time": "2019-01-03T07:32:24.296303Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_binary_proportion_comparison(\n",
    "    ['Male', 'Female'], [screen_time_male_by_show, screen_time_female_by_show],\n",
    "    'Gender Distribution of Screen Time vs. Show', '', 'Proportion of Screen Time',\n",
    "    raw_data_to_label_fn=None, legend_loc=4,\n",
    "    baseline_series_names=[\n",
    "        'Baseline Male (Entire Dataset)', \n",
    "        'Baseline Female (Entire Dataset)'\n",
    "    ],\n",
    "    baseline_data=[\n",
    "        screen_time_male['All Channels'][0],\n",
    "        screen_time_female['All Channels'][0]\n",
    "    ],\n",
    "    save_path='figures/gender-10y-screen-time-by-show.pdf',\n",
    "    figsize=(30, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T07:43:10.306271Z",
     "start_time": "2019-01-03T07:32:27.961351Z"
    }
   },
   "outputs": [],
   "source": [
    "screen_time_nh_male_by_show, screen_time_nh_female_by_show = {}, {}\n",
    "for k, v in sum_over_column(face_genders_nh, 'duration', ['canonical_show_id'],\n",
    "                            probability_column='male_probability').items():\n",
    "    if k[0] in canonical_show_map:\n",
    "        screen_time_nh_male_by_show[canonical_show_map[k[0]]] = v\n",
    "for k, v in sum_over_column(face_genders_nh, 'duration', ['canonical_show_id'], \n",
    "                            probability_column='female_probability').items():\n",
    "    if k[0] in canonical_show_map:\n",
    "        screen_time_nh_female_by_show[canonical_show_map[k[0]]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T07:43:13.381770Z",
     "start_time": "2019-01-03T07:43:10.317434Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_binary_proportion_comparison(\n",
    "    ['Male (Excl. Hosts)', 'Female (Excl. Hosts)'], [screen_time_nh_male_by_show, screen_time_nh_female_by_show],\n",
    "    'Gender Distribution of Screen Time (Excluding Hosts) vs. Show', '', 'Proportion of Screen Time',\n",
    "    tertiary_series_names=['Male (Incl. Hosts)', 'Female (Incl. Hosts)'],\n",
    "    tertiary_data=[screen_time_male_by_show, screen_time_female_by_show],\n",
    "#     baseline_data=[\n",
    "#         screen_time_male['All Channels'][0],\n",
    "#         screen_time_female['All Channels'][0]\n",
    "#     ],\n",
    "#     baseline_series_names=[\n",
    "#         'Baseline Male (Entire Dataset)', \n",
    "#         'Baseline Female (Entire Dataset)'\n",
    "#     ],\n",
    "    raw_data_to_label_fn=None, legend_loc=4,\n",
    "    save_path='figures/gender-10y-screen-time-by-show-no-host.pdf',\n",
    "    figsize=(30, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Gender CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T22:28:09.142652Z",
     "start_time": "2019-01-05T22:28:05.293600Z"
    }
   },
   "outputs": [],
   "source": [
    "channel_id_to_name = {c.id: c.name for c in Channel.objects.all()}\n",
    "cshow_id_to_name = {c.id: c.name for c in CanonicalShow.objects.all()}\n",
    "video_id_to_path = {v.id: v.path for v in Video.objects.all()}\n",
    "color_id_to_name = {c.id: c.name for c in HairColorName.objects.all()}\n",
    "clothing_id_to_name = {c.id: c.name for c in ClothingName.objects.all()}\n",
    "\n",
    "def get_date_hour_from_path(t):\n",
    "    tokens = t.split('_')\n",
    "    yyyymmdd = tokens[1]\n",
    "    hhmmss = tokens[2]\n",
    "    hour = int(hhmmss[:2])\n",
    "    date = yyyymmdd[:4] + '-' + yyyymmdd[4:6] + '-' + yyyymmdd[6:]\n",
    "    return date, hour\n",
    "\n",
    "def get_isoweekday(date):\n",
    "    dt = datetime.strptime(date, '%Y-%m-%d')\n",
    "    return dt.isoweekday()\n",
    "\n",
    "assert get_isoweekday('2018-09-07') == 5\n",
    "assert get_date_hour_from_path('tvnews/videos/MSNBCW_20180821_230000_Hardball_With_Chris_Matthews.mp4') == ('2018-08-21', 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summing over male faces')\n",
    "male_st = sum_over_column(\n",
    "    face_genders, 'duration',\n",
    "    ['video_id', 'channel_id', 'canonical_show_id', 'in_commercial', 'is_host2', 'height2', \n",
    "     'haircolor_id', 'clothing_id'],\n",
    "    probability_column='male_probability'\n",
    ")\n",
    "\n",
    "print('Summing over female faces')\n",
    "female_st = sum_over_column(\n",
    "    face_genders, 'duration',\n",
    "    ['video_id', 'channel_id', 'canonical_show_id', 'in_commercial', 'is_host2', 'height2', \n",
    "     'haircolor_id', 'clothing_id'],\n",
    "    probability_column='female_probability'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:37:57.693721Z",
     "start_time": "2019-01-05T23:14:41.999432Z"
    }
   },
   "outputs": [],
   "source": [
    "gender_outfile = '/app/data/gender_10y.csv'\n",
    "\n",
    "with open(gender_outfile, 'w') as f:\n",
    "    f.write(','.join([\n",
    "        'gender', \n",
    "        'video_id',\n",
    "#         'video_path',\n",
    "        'channel',\n",
    "        'canonical_show',\n",
    "        'date',\n",
    "        'hour',\n",
    "        'isoweekday', \n",
    "        'in_commercial', \n",
    "        'is_host',\n",
    "        'bbox_height_leq',\n",
    "        'hair_color',\n",
    "        'clothing',\n",
    "        'screentime_seconds',\n",
    "        'variance_seconds_sq'\n",
    "    ]))\n",
    "    f.write('\\r\\n')\n",
    "    \n",
    "    def write_row(g, k, v):\n",
    "        video_id, channel_id, cshow_id, in_comm, is_host, bbox_height, color_id, clothing_id = k\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        week_day = get_isoweekday(date)\n",
    "        row = [\n",
    "            g,\n",
    "            str(video_id), \n",
    "#             video_path, \n",
    "            channel_id_to_name[channel_id], \n",
    "            cshow_id_to_name[cshow_id],\n",
    "            date,\n",
    "            str(hour),\n",
    "            str(week_day), \n",
    "            str(in_comm), \n",
    "            str(is_host),\n",
    "            str(bbox_height),\n",
    "            color_id_to_name.get(color_id, ''),\n",
    "            clothing_id_to_name.get(clothing_id, ''),\n",
    "            str(v[0]),\n",
    "            str(v[1])\n",
    "        ]\n",
    "        f.write(','.join(row))\n",
    "        f.write('\\r\\n')\n",
    "    \n",
    "    def sort_fn(k):\n",
    "        video_id, channel_id, cshow_id, in_comm, is_host, bbox_height, color_id, clothing_id = k\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        return date, hour, video_id\n",
    "\n",
    "    row_count = 0\n",
    "    for k in sorted(set(female_st) | set(male_st), key=sort_fn):\n",
    "        if k in male_st:\n",
    "            write_row('m', k, male_st[k])\n",
    "        if k in female_st:\n",
    "            write_row('f', k, female_st[k])\n",
    "        row_count += 1\n",
    "    \n",
    "    print('Wrote {} rows'.format(row_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:47:21.750334Z",
     "start_time": "2019-01-05T23:39:42.940275Z"
    }
   },
   "outputs": [],
   "source": [
    "face_idents = get_face_identities(include_name=True)\n",
    "# face_idents = face_idents.withColumn('date', func.date_format('time', 'yyyy-MM-dd'))\n",
    "# face_idents = face_idents.withColumn('is_host2', face_idents.host_probability > 0.5)\n",
    "face_idents = face_idents.withColumn(\n",
    "    'height2', func.ceil(face_idents.height * 100 / 10) * 10)\n",
    "\n",
    "ident_st = sum_over_column(\n",
    "    face_idents, 'duration', \n",
    "    ['name', 'video_id', 'channel_id', 'canonical_show_id', 'in_commercial', 'height2',\n",
    "     'haircolor_id', 'clothing_id'],\n",
    "    probability_column='probability'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:53:29.333222Z",
     "start_time": "2019-01-05T23:47:21.754027Z"
    }
   },
   "outputs": [],
   "source": [
    "ident_outfile = '/app/data/identity_10y.csv'\n",
    "\n",
    "with open(ident_outfile, 'w') as f:\n",
    "    f.write(','.join([\n",
    "        'name',\n",
    "        'video_id',\n",
    "#         'video_path',\n",
    "        'channel', \n",
    "        'canonical_show', \n",
    "        'date', \n",
    "        'hour',\n",
    "        'isoweekday', \n",
    "        'in_commercial',\n",
    "        'hair_color',\n",
    "        'clothing',\n",
    "        'bbox_height_leq',\n",
    "        'screentime_seconds', \n",
    "        'variance_seconds_sq'\n",
    "    ]))\n",
    "    f.write('\\r\\n')\n",
    "    \n",
    "    def write_row(k, v):\n",
    "        name, video_id, channel_id, cshow_id, in_comm, bbox_height, color_id, clothing_id = k\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        week_day = get_isoweekday(date)\n",
    "        row = [\n",
    "            name,\n",
    "            str(video_id),\n",
    "#             video_path,\n",
    "            channel_id_to_name[channel_id], \n",
    "            cshow_id_to_name[cshow_id],\n",
    "            date, \n",
    "            str(hour),\n",
    "            str(week_day),\n",
    "            str(in_comm),\n",
    "            str(bbox_height),\n",
    "            color_id_to_name.get(color_id, ''),\n",
    "            clothing_id_to_name.get(clothing_id, ''),\n",
    "            str(v[0]),\n",
    "            str(v[1])\n",
    "        ]\n",
    "        f.write(','.join(row))\n",
    "        f.write('\\r\\n')\n",
    "    \n",
    "    def sort_fn(k):\n",
    "        name, video_id, channel_id, cshow_id, in_comm, bbox_height, color_id, clothing_id = k\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        return name, date, video_path\n",
    "    \n",
    "    print('Summing over identities')\n",
    "    row_count = 0\n",
    "    for k in sorted(ident_st, key=sort_fn):\n",
    "        write_row(k, ident_st[k])\n",
    "        row_count += 1\n",
    "    \n",
    "    print('Wrote {} rows'.format(row_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T04:42:39.584464Z",
     "start_time": "2019-01-06T04:42:39.535291Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Computing video id to commercials')\n",
    "VIDEO_ID_TO_COMMERCIALS = defaultdict(list)\n",
    "for c in get_commercials().select('video_id', 'min_frame', 'max_frame').collect():\n",
    "    VIDEO_ID_TO_COMMERCIALS[c.video_id].append(\n",
    "        (c.min_frame, c.max_frame)\n",
    "    )\n",
    "    \n",
    "def _annotate_frame_in_commercial(df):\n",
    "    assert ('video_id' in df.columns)\n",
    "    assert ('number' in df.columns)\n",
    "    def in_commercial_helper(video_id, frame_no):\n",
    "        if video_id in VIDEO_ID_TO_COMMERCIALS:\n",
    "            for c_min, c_max in VIDEO_ID_TO_COMMERCIALS[video_id]:\n",
    "                if frame_no >= c_min and frame_no <= c_max:\n",
    "                    return True\n",
    "        return False\n",
    "    my_udf = func.udf(in_commercial_helper, BooleanType())\n",
    "    df = df.withColumn(\n",
    "        'in_commercial', my_udf('video_id', 'number')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "print('Computing frames with host')\n",
    "if True:\n",
    "    frames_w_host_df = faces.where(\n",
    "        faces.host_probability > 0.5\n",
    "    ).select('frame_id').distinct()\n",
    "    spark.save('frames_w_host', frames_w_host_df)\n",
    "\n",
    "print('Computing frames to face count')\n",
    "if True:\n",
    "    frames_face_count_df = faces.groupBy(\n",
    "        'frame_id'\n",
    "    ).agg(\n",
    "        func.count(func.lit(1)).alias('face_count')\n",
    "    )\n",
    "    spark.save('frames_face_count', frames_face_count_df)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T04:42:58.768673Z",
     "start_time": "2019-01-06T04:42:47.389707Z"
    }
   },
   "outputs": [],
   "source": [
    "videos = get_videos()\n",
    "videos = videos.where((videos.duplicate == False) & (videos.corrupted == False))\n",
    "frames = get_frames()\n",
    "frames_with_host = spark.load('frames_w_host').withColumn('has_host', func.lit(True))\n",
    "frames_face_count = spark.load('frames_face_count')\n",
    "frames = frames.join(\n",
    "    videos, frames.video_id == videos.id\n",
    ").join(\n",
    "    frames_with_host, frames.id == frames_with_host.frame_id, 'left_outer'\n",
    ").join(\n",
    "    frames_face_count, frames.id == frames_face_count.frame_id, 'left_outer'\n",
    ").select(\n",
    "    'frames.*',\n",
    "    videos.channel_id,\n",
    "    videos.canonical_show_id,\n",
    "    frames_with_host.has_host,\n",
    "    frames_face_count.face_count\n",
    ").where(\n",
    "    ((videos.threeyears_dataset == True) & (frames.number % func.floor(videos.fps * 3) == 0)) | \\\n",
    "    ((videos.threeyears_dataset == False) & (frames.number % func.ceil(videos.fps * 3) == 0))\n",
    ")\n",
    "frames = _annotate_frame_in_commercial(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T05:00:28.201389Z",
     "start_time": "2019-01-06T04:56:43.895430Z"
    }
   },
   "outputs": [],
   "source": [
    "video_outfile = '/app/data/video_10y.csv'\n",
    "\n",
    "print('Summing over frames')\n",
    "with open(video_outfile, 'w') as f:\n",
    "    f.write(','.join([\n",
    "        'video_id',\n",
    "#         'video_path',\n",
    "        'channel', \n",
    "        'canonical_show', \n",
    "        'date', \n",
    "        'hour',\n",
    "        'isoweekday', \n",
    "        'in_commercial', \n",
    "        'host_onscreen',\n",
    "        'num_faces_onscreen',\n",
    "        'screentime_seconds'\n",
    "    ]))\n",
    "    f.write('\\r\\n')\n",
    "    \n",
    "    row_count = 0\n",
    "    for row in frames.groupBy(\n",
    "        'video_id', 'channel_id', 'canonical_show_id', 'in_commercial', 'has_host', 'face_count'\n",
    "    ).agg(\n",
    "        func.count(func.lit(1)).alias('frame_count')\n",
    "    ).sort(\n",
    "        'channel_id', 'canonical_show_id', 'video_id', 'in_commercial', 'has_host', 'face_count'\n",
    "    ).collect():\n",
    "        video_id = row.video_id\n",
    "        channel_id = row.channel_id\n",
    "        cshow_id = row.canonical_show_id\n",
    "        in_comm = row.in_commercial\n",
    "        has_host = row.has_host == True\n",
    "        face_count = row.face_count\n",
    "        if face_count is None:\n",
    "            face_count = 0\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        week_day = get_isoweekday(date)\n",
    "        f.write(','.join([\n",
    "            str(video_id),\n",
    "#             video_path,\n",
    "            channel_id_to_name[channel_id], \n",
    "            cshow_id_to_name[cshow_id],\n",
    "            date, \n",
    "            str(hour),\n",
    "            str(week_day),\n",
    "            str(in_comm), \n",
    "            str(has_host),\n",
    "            str(face_count),\n",
    "            str(row.frame_count * 3)\n",
    "        ]))\n",
    "        f.write('\\r\\n')\n",
    "        row_count += 1\n",
    "    print('Wrote {} rows'.format(row_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T04:24:24.039813Z",
     "start_time": "2019-01-05T04:24:23.914518Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
