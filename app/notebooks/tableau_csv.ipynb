{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T19:38:35.616902Z",
     "start_time": "2019-01-10T19:38:30.960579Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "from datetime import timedelta, datetime\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "\n",
    "from esper.widget import *\n",
    "from esper.prelude import *\n",
    "from esper.spark_util import *\n",
    "from esper.validation import *\n",
    "from esper.plot_util import *\n",
    "from esper.spark_identity import get_screen_time_by_canonical_show_spark\n",
    "from esper.major_canonical_shows import MAJOR_CANONICAL_SHOWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T19:38:37.978392Z",
     "start_time": "2019-01-10T19:38:37.815247Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from datetime import tzinfo, timedelta, datetime, timezone\n",
    "import copy\n",
    "\n",
    "ZERO = timedelta(0)\n",
    "HOUR = timedelta(hours=1)\n",
    "SECOND = timedelta(seconds=1)\n",
    "\n",
    "# A class capturing the platform's idea of local time.\n",
    "# (May result in wrong values on historical times in\n",
    "#  timezones where UTC offset and/or the DST rules had\n",
    "#  changed in the past.)\n",
    "import time as _time\n",
    "\n",
    "STDOFFSET = timedelta(seconds = -_time.timezone)\n",
    "if _time.daylight:\n",
    "    DSTOFFSET = timedelta(seconds = -_time.altzone)\n",
    "else:\n",
    "    DSTOFFSET = STDOFFSET\n",
    "\n",
    "DSTDIFF = DSTOFFSET - STDOFFSET\n",
    "\n",
    "# A complete implementation of current DST rules for major US time zones.\n",
    "\n",
    "def first_sunday_on_or_after(dt):\n",
    "    days_to_go = 6 - dt.weekday()\n",
    "    if days_to_go:\n",
    "        dt += timedelta(days_to_go)\n",
    "    return dt\n",
    "\n",
    "\n",
    "# US DST Rules\n",
    "#\n",
    "# This is a simplified (i.e., wrong for a few cases) set of rules for US\n",
    "# DST start and end times. For a complete and up-to-date set of DST rules\n",
    "# and timezone definitions, visit the Olson Database (or try pytz):\n",
    "# http://www.twinsun.com/tz/tz-link.htm\n",
    "# http://sourceforge.net/projects/pytz/ (might not be up-to-date)\n",
    "#\n",
    "# In the US, since 2007, DST starts at 2am (standard time) on the second\n",
    "# Sunday in March, which is the first Sunday on or after Mar 8.\n",
    "DSTSTART_2007 = datetime(1, 3, 8, 2)\n",
    "# and ends at 2am (DST time) on the first Sunday of Nov.\n",
    "DSTEND_2007 = datetime(1, 11, 1, 2)\n",
    "# From 1987 to 2006, DST used to start at 2am (standard time) on the first\n",
    "# Sunday in April and to end at 2am (DST time) on the last\n",
    "# Sunday of October, which is the first Sunday on or after Oct 25.\n",
    "DSTSTART_1987_2006 = datetime(1, 4, 1, 2)\n",
    "DSTEND_1987_2006 = datetime(1, 10, 25, 2)\n",
    "# From 1967 to 1986, DST used to start at 2am (standard time) on the last\n",
    "# Sunday in April (the one on or after April 24) and to end at 2am (DST time)\n",
    "# on the last Sunday of October, which is the first Sunday\n",
    "# on or after Oct 25.\n",
    "DSTSTART_1967_1986 = datetime(1, 4, 24, 2)\n",
    "DSTEND_1967_1986 = DSTEND_1987_2006\n",
    "\n",
    "def us_dst_range(year):\n",
    "    # Find start and end times for US DST. For years before 1967, return\n",
    "    # start = end for no DST.\n",
    "    if 2006 < year:\n",
    "        dststart, dstend = DSTSTART_2007, DSTEND_2007\n",
    "    elif 1986 < year < 2007:\n",
    "        dststart, dstend = DSTSTART_1987_2006, DSTEND_1987_2006\n",
    "    elif 1966 < year < 1987:\n",
    "        dststart, dstend = DSTSTART_1967_1986, DSTEND_1967_1986\n",
    "    else:\n",
    "        return (datetime(year, 1, 1), ) * 2\n",
    "\n",
    "    start = first_sunday_on_or_after(dststart.replace(year=year))\n",
    "    end = first_sunday_on_or_after(dstend.replace(year=year))\n",
    "    return start, end\n",
    "\n",
    "\n",
    "class USTimeZone(tzinfo):\n",
    "\n",
    "    def __init__(self, hours, reprname, stdname, dstname):\n",
    "        self.stdoffset = timedelta(hours=hours)\n",
    "        self.reprname = reprname\n",
    "        self.stdname = stdname\n",
    "        self.dstname = dstname\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.reprname\n",
    "\n",
    "    def tzname(self, dt):\n",
    "        if self.dst(dt):\n",
    "            return self.dstname\n",
    "        else:\n",
    "            return self.stdname\n",
    "\n",
    "    def utcoffset(self, dt):\n",
    "        return self.stdoffset + self.dst(dt)\n",
    "\n",
    "    def dst(self, dt):\n",
    "        if dt is None or dt.tzinfo is None:\n",
    "            # An exception may be sensible here, in one or both cases.\n",
    "            # It depends on how you want to treat them.  The default\n",
    "            # fromutc() implementation (called by the default astimezone()\n",
    "            # implementation) passes a datetime with dt.tzinfo is self.\n",
    "            return ZERO\n",
    "        assert dt.tzinfo is self\n",
    "        start, end = us_dst_range(dt.year)\n",
    "        # Can't compare naive to aware objects, so strip the timezone from\n",
    "        # dt first.\n",
    "        dt = dt.replace(tzinfo=None)\n",
    "        if start + HOUR <= dt < end - HOUR:\n",
    "            # DST is in effect.\n",
    "            return HOUR\n",
    "        if end - HOUR <= dt < end:\n",
    "            # Fold (an ambiguous hour): use dt.fold to disambiguate.\n",
    "            return ZERO if dt.fold else HOUR\n",
    "        if start <= dt < start + HOUR:\n",
    "            # Gap (a non-existent hour): reverse the fold rule.\n",
    "            return HOUR if dt.fold else ZERO\n",
    "        # DST is off.\n",
    "        return ZERO\n",
    "\n",
    "    def fromutc(self, dt):\n",
    "        assert dt.tzinfo is self\n",
    "        start, end = us_dst_range(dt.year)\n",
    "        start = start.replace(tzinfo=self)\n",
    "        end = end.replace(tzinfo=self)\n",
    "        std_time = dt + self.stdoffset\n",
    "        dst_time = std_time + HOUR\n",
    "        if end <= dst_time < end + HOUR:\n",
    "            # Repeated hour\n",
    "            new_time = copy.copy(std_time)\n",
    "            return new_time #std_time.replace(fold=1)\n",
    "        if std_time < start or dst_time >= end:\n",
    "            # Standard time\n",
    "            return std_time\n",
    "        if start <= std_time < end - HOUR:\n",
    "            # Daylight saving time\n",
    "            return dst_time\n",
    "\n",
    "\n",
    "Eastern  = USTimeZone(-5, \"Eastern\",  \"EST\", \"EDT\")\n",
    "Central  = USTimeZone(-6, \"Central\",  \"CST\", \"CDT\")\n",
    "Mountain = USTimeZone(-7, \"Mountain\", \"MST\", \"MDT\")\n",
    "Pacific  = USTimeZone(-8, \"Pacific\",  \"PST\", \"PDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T19:38:45.861508Z",
     "start_time": "2019-01-10T19:38:39.309024Z"
    }
   },
   "outputs": [],
   "source": [
    "channel_id_to_name = {c.id: c.name for c in Channel.objects.all()}\n",
    "cshow_id_to_name = {c.id: c.name for c in CanonicalShow.objects.all()}\n",
    "video_id_to_path = {v.id: v.path for v in Video.objects.all()}\n",
    "# color_id_to_name = {c.id: c.name for c in HairColorName.objects.all()}\n",
    "color_id_to_name = {1: 'blond', 2: 'dark', 3: 'white', 4: 'dark', 5: 'dark', 6: ''}\n",
    "length_id_to_name = {c.id: c.name for c in HairLengthName.objects.all()}\n",
    "clothing_id_to_name = {c.id: c.name for c in ClothingName.objects.all()}\n",
    "gender_id_to_name = {g.id: g.name for g in Gender.objects.all()}\n",
    "\n",
    "channel_id_to_host_ids = defaultdict(set)\n",
    "for v in Video.objects.distinct('show__canonical_show'):\n",
    "    channel_id_to_host_ids[v.channel.id].update([\n",
    "        h.name for h in v.show.canonical_show.hosts.all()\n",
    "    ])\n",
    "\n",
    "def get_identity_is_host(channel_id, ident_name):\n",
    "    assert channel_id in channel_id_to_host_ids\n",
    "    return ident_name in channel_id_to_host_ids[channel_id]\n",
    "\n",
    "def get_date_hour_from_path(t):\n",
    "    tokens = t.split('_')\n",
    "    yyyymmdd = tokens[1]\n",
    "    hhmmss = tokens[2]\n",
    "    gmt = datetime(int(yyyymmdd[:4]), int(yyyymmdd[4:6]), int(yyyymmdd[6:]), \\\n",
    "                           int(hhmmss[:2]), tzinfo=timezone.utc)\n",
    "    est = gmt.astimezone(Eastern)\n",
    "    date = '{:04}-{:02}-{:02}'.format(est.year, est.month, est.day)\n",
    "    hour = est.hour\n",
    "    return date, hour\n",
    "\n",
    "def get_isoweekday(date):\n",
    "    dt = datetime.strptime(date, '%Y-%m-%d')\n",
    "    return dt.isoweekday()\n",
    "\n",
    "def get_height_udf(sat, max_val=100):\n",
    "    def height_udf(h):\n",
    "        return h if h < sat else max_val\n",
    "    return func.udf(height_udf, IntegerType())\n",
    "\n",
    "assert get_isoweekday('2018-09-07') == 5\n",
    "assert get_date_hour_from_path('tvnews/videos/MSNBCW_20190109_020000_Hardball_With_Chris_Matthews.mp4') == ('2019-01-08', 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T19:58:31.735073Z",
     "start_time": "2019-01-10T19:38:45.864468Z"
    }
   },
   "outputs": [],
   "source": [
    "faces = get_faces()\n",
    "face_genders = get_face_genders()\n",
    "face_genders = face_genders.where(\n",
    "    face_genders.labeler_id == Labeler.objects.get(name='rudecarnie').id)\n",
    "      \n",
    "face_genders = face_genders.withColumn('is_host2', face_genders.host_probability > 0.5)\n",
    "face_genders = face_genders.withColumn('height_gte20', face_genders.height >= 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Gender Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T22:49:25.161230Z",
     "start_time": "2019-01-08T22:31:01.451740Z"
    }
   },
   "outputs": [],
   "source": [
    "face_genders_nh = face_genders.where(face_genders.host_probability < 0.5)\n",
    "screen_time_male, screen_time_female = OrderedDict(), OrderedDict()\n",
    "screen_time_nh_male, screen_time_nh_female = OrderedDict(), OrderedDict()\n",
    "\n",
    "print('Computing screen time across all channels')\n",
    "screen_time_male['All Channels'] = sum_over_column(\n",
    "    face_genders, 'duration', probability_column='male_probability'\n",
    ")\n",
    "screen_time_female['All Channels'] = sum_over_column(\n",
    "    face_genders, 'duration', probability_column='female_probability'\n",
    ")\n",
    "\n",
    "print('Computing screen time across all channels (non-hosts)')\n",
    "screen_time_nh_male['All Channels'] = sum_over_column(\n",
    "    face_genders_nh, 'duration', probability_column='male_probability'\n",
    ")\n",
    "screen_time_nh_female['All Channels'] = sum_over_column(\n",
    "    face_genders_nh, 'duration', probability_column='female_probability'\n",
    ")\n",
    "\n",
    "# print('Computing screen time by channel')\n",
    "# channel_id_map = {c.id : c.name for c in Channel.objects.all()}\n",
    "# for k, v in sum_over_column(face_genders, 'duration', ['channel_id'], \n",
    "#                             probability_column='male_probability').items():\n",
    "#     screen_time_male[channel_id_map[k[0]]] = v\n",
    "# for k, v in sum_over_column(face_genders, 'duration', ['channel_id'], \n",
    "#                             probability_column='female_probability').items():\n",
    "#     screen_time_female[channel_id_map[k[0]]] = v\n",
    "    \n",
    "# print('Computing screen time by channel (non-host)')\n",
    "# for k, v in sum_over_column(face_genders_nh, 'duration', ['channel_id'], \n",
    "#                             probability_column='male_probability').items():\n",
    "#     screen_time_nh_male[channel_id_map[k[0]]] = v\n",
    "# for k, v in sum_over_column(face_genders_nh, 'duration', ['channel_id'], \n",
    "#                             probability_column='female_probability').items():\n",
    "#     screen_time_nh_female[channel_id_map[k[0]]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T06:27:46.529912Z",
     "start_time": "2019-01-03T06:27:33.050Z"
    }
   },
   "outputs": [],
   "source": [
    "# sort_order = ['All Channels'] + [c.name for c in Channel.objects.all().order_by('name')]\n",
    "# plot_binary_proportion_comparison(\n",
    "#     ['Male', 'Female'], [screen_time_male, screen_time_female],\n",
    "#     '', '', 'Proportion of Screen Time',\n",
    "#     raw_data_to_label_fn=None, figsize=(5,5), sort_order=sort_order,\n",
    "#     legend_loc=4,\n",
    "#     save_path='figures/gender-10y-screen-time.pdf'\n",
    "# )\n",
    "# plot_binary_proportion_comparison(\n",
    "#     ['Male', 'Female'], [screen_time_nh_male, screen_time_nh_female],\n",
    "#     '', '', 'Proportion of Screen Time (Excluding Hosts)',\n",
    "#     raw_data_to_label_fn=None, figsize=(5,5), sort_order=sort_order,\n",
    "#     legend_loc=4,\n",
    "#     save_path='figures/gender-10y-screen-time-no-host.pdf'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T22:53:08.328275Z",
     "start_time": "2019-01-08T22:49:25.164026Z"
    }
   },
   "outputs": [],
   "source": [
    "canonical_show_map = {c.id : c.name for c in CanonicalShow.objects.all() if c.name in MAJOR_CANONICAL_SHOWS}\n",
    "screen_time_male_by_show, screen_time_female_by_show = {}, {}\n",
    "for k, v in sum_over_column(face_genders, 'duration', ['canonical_show_id'],\n",
    "                            probability_column='male_probability').items():\n",
    "    if k[0] in canonical_show_map:\n",
    "        screen_time_male_by_show[canonical_show_map[k[0]]] = v\n",
    "for k, v in sum_over_column(face_genders, 'duration', ['canonical_show_id'], \n",
    "                            probability_column='female_probability').items():\n",
    "    if k[0] in canonical_show_map:\n",
    "        screen_time_female_by_show[canonical_show_map[k[0]]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T22:53:11.478792Z",
     "start_time": "2019-01-08T22:53:08.330108Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_binary_proportion_comparison(\n",
    "    ['Male', 'Female'], [screen_time_male_by_show, screen_time_female_by_show],\n",
    "    'Gender Distribution of Screen Time vs. Show', '', 'Proportion of Screen Time',\n",
    "    raw_data_to_label_fn=None, legend_loc=4,\n",
    "    baseline_series_names=[\n",
    "        'Baseline Male (Entire Dataset)', \n",
    "        'Baseline Female (Entire Dataset)'\n",
    "    ],\n",
    "    baseline_data=[\n",
    "        screen_time_male['All Channels'][0],\n",
    "        screen_time_female['All Channels'][0]\n",
    "    ],\n",
    "    save_path='figures/gender-10y-screen-time-by-show.pdf',\n",
    "    figsize=(30, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T23:06:17.806633Z",
     "start_time": "2019-01-08T22:53:11.481577Z"
    }
   },
   "outputs": [],
   "source": [
    "screen_time_nh_male_by_show, screen_time_nh_female_by_show = {}, {}\n",
    "for k, v in sum_over_column(face_genders_nh, 'duration', ['canonical_show_id'],\n",
    "                            probability_column='male_probability').items():\n",
    "    if k[0] in canonical_show_map:\n",
    "        screen_time_nh_male_by_show[canonical_show_map[k[0]]] = v\n",
    "for k, v in sum_over_column(face_genders_nh, 'duration', ['canonical_show_id'], \n",
    "                            probability_column='female_probability').items():\n",
    "    if k[0] in canonical_show_map:\n",
    "        screen_time_nh_female_by_show[canonical_show_map[k[0]]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T23:06:20.877355Z",
     "start_time": "2019-01-08T23:06:17.809279Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_binary_proportion_comparison(\n",
    "    ['Male (Excl. Hosts)', 'Female (Excl. Hosts)'], [screen_time_nh_male_by_show, screen_time_nh_female_by_show],\n",
    "    'Gender Distribution of Screen Time (Excluding Hosts) vs. Show', '', 'Proportion of Screen Time',\n",
    "    tertiary_series_names=['Male (Incl. Hosts)', 'Female (Incl. Hosts)'],\n",
    "    tertiary_data=[screen_time_male_by_show, screen_time_female_by_show],\n",
    "#     baseline_data=[\n",
    "#         screen_time_male['All Channels'][0],\n",
    "#         screen_time_female['All Channels'][0]\n",
    "#     ],\n",
    "#     baseline_series_names=[\n",
    "#         'Baseline Male (Entire Dataset)', \n",
    "#         'Baseline Female (Entire Dataset)'\n",
    "#     ],\n",
    "    raw_data_to_label_fn=None, legend_loc=4,\n",
    "    save_path='figures/gender-10y-screen-time-by-show-no-host.pdf',\n",
    "    figsize=(30, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Gender CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T00:38:24.354989Z",
     "start_time": "2019-01-10T00:02:05.068320Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Summing over male faces')\n",
    "male_st = sum_over_column(\n",
    "    face_genders, 'duration',\n",
    "    ['video_id', 'channel_id', 'canonical_show_id', 'in_commercial', 'is_host2', 'height_gte20', \n",
    "     'haircolor_id', 'clothing_id', 'hairlength_id'],\n",
    "    probability_column='male_probability'\n",
    ")\n",
    "\n",
    "print('Summing over female faces')\n",
    "female_st = sum_over_column(\n",
    "    face_genders, 'duration',\n",
    "    ['video_id', 'channel_id', 'canonical_show_id', 'in_commercial', 'is_host2', 'height_gte20', \n",
    "     'haircolor_id', 'clothing_id', 'hairlength_id'],\n",
    "    probability_column='female_probability'\n",
    ")\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:07:25.904625Z",
     "start_time": "2019-01-10T00:38:24.372222Z"
    }
   },
   "outputs": [],
   "source": [
    "gender_outfile = '/app/data/gender_10y.csv'\n",
    "\n",
    "with open(gender_outfile, 'w') as f:\n",
    "    f.write(','.join([\n",
    "        'gender', \n",
    "        'video_id',\n",
    "#         'video_path',\n",
    "        'channel',\n",
    "        'canonical_show',\n",
    "        'date',\n",
    "        'hour',\n",
    "        'isoweekday', \n",
    "        'in_commercial', \n",
    "        'is_host',\n",
    "        'height_gte20',\n",
    "        'hair_color',\n",
    "        'hair_length',\n",
    "        'clothing',\n",
    "        'screentime_seconds',\n",
    "        'variance_seconds_sq'\n",
    "    ]))\n",
    "    f.write('\\r\\n')\n",
    "    \n",
    "    def write_row(g, k, v):\n",
    "        video_id, channel_id, cshow_id, in_comm, is_host, bbox_height, color_id, clothing_id, length_id = k\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        week_day = get_isoweekday(date)\n",
    "        row = [\n",
    "            g,\n",
    "            str(video_id), \n",
    "#             video_path, \n",
    "            channel_id_to_name[channel_id], \n",
    "            cshow_id_to_name[cshow_id],\n",
    "            date,\n",
    "            str(hour),\n",
    "            str(week_day), \n",
    "            str(in_comm), \n",
    "            str(is_host),\n",
    "            str(bbox_height),\n",
    "            color_id_to_name.get(color_id, ''),\n",
    "            length_id_to_name.get(length_id, ''),\n",
    "            clothing_id_to_name.get(clothing_id, ''),\n",
    "            str(v[0]),\n",
    "            str(v[1])\n",
    "        ]\n",
    "        f.write(','.join(row))\n",
    "        f.write('\\r\\n')\n",
    "    \n",
    "    def sort_fn(k):\n",
    "        video_id, channel_id, cshow_id, in_comm, is_host, bbox_height, color_id, clothing_id, length_id = k\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        return date, hour, video_id\n",
    "\n",
    "    row_count = 0\n",
    "    for k in sorted(set(female_st) | set(male_st), key=sort_fn):\n",
    "        if k in male_st:\n",
    "            write_row('m', k, male_st[k])\n",
    "        if k in female_st:\n",
    "            write_row('f', k, female_st[k])\n",
    "        row_count += 1\n",
    "        if row_count % 10000 == 0:\n",
    "            print('  {} / {}'.format(row_count, len(female_st) + len(male_st)))\n",
    "    \n",
    "    print('Wrote {} rows'.format(row_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T20:05:33.439857Z",
     "start_time": "2019-01-10T19:58:31.737706Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "face_idents = get_face_identities(include_name=True)\n",
    "# face_idents = face_idents.withColumn('date', func.date_format('time', 'yyyy-MM-dd'))\n",
    "# face_idents = face_idents.withColumn('is_host2', face_idents.host_probability > 0.5)\n",
    "face_genders_basic = spark.load('query_facegender')\n",
    "face_genders_basic = face_genders_basic.where(face_genders_basic.labeler_id == Labeler.objects.get(name='rudecarnie').id)\n",
    "face_idents = face_idents.join(\n",
    "    face_genders_basic.select('face_id', 'gender_id'), \n",
    "    face_idents.face_id == face_genders_basic.face_id, 'left_outer'\n",
    ").select(\n",
    "    *[c if c != 'face_id' else 'face_identities.face_id' for c in face_idents.columns], \n",
    "    face_genders_basic.gender_id\n",
    ")\n",
    "face_idents = face_idents.withColumn('height_gte20', face_idents.height >= 0.2)\n",
    "\n",
    "print('Summing over identities')\n",
    "ident_st = sum_over_column(\n",
    "    face_idents, 'duration', \n",
    "    ['name', 'video_id', 'channel_id', 'canonical_show_id', 'in_commercial', 'height_gte20',\n",
    "     'haircolor_id', 'hairlength_id', 'clothing_id', 'gender_id'],\n",
    "    probability_column='probability'\n",
    ")\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T20:05:54.173614Z",
     "start_time": "2019-01-10T20:05:33.442430Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Computing true genders')\n",
    "def ident_to_true_gender(ident_st):\n",
    "    ident_mf_diff = {}\n",
    "    for k in ident_st:\n",
    "        name = k[0]\n",
    "        gender = gender_id_to_name.get(k[-1], '')\n",
    "        if name not in ident_mf_diff:\n",
    "            ident_mf_diff[name] = 0.\n",
    "        if gender == 'M':\n",
    "            ident_mf_diff[name] += ident_st[k][0]\n",
    "        elif gender == 'F':\n",
    "            ident_mf_diff[name] -= ident_st[k][0]\n",
    "    return {k: 'M' if v >= 0 else 'F' for k, v in ident_mf_diff.items()}\n",
    "name_to_true_gender = ident_to_true_gender(ident_st)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T20:17:18.446967Z",
     "start_time": "2019-01-10T20:05:54.175815Z"
    }
   },
   "outputs": [],
   "source": [
    "ident_outfile = '/app/data/identity_10y.csv'\n",
    "\n",
    "with open(ident_outfile, 'w') as f:\n",
    "    f.write(','.join([\n",
    "        'name',\n",
    "        'video_id',\n",
    "#         'video_path',\n",
    "        'channel', \n",
    "        'canonical_show', \n",
    "        'date', \n",
    "        'hour',\n",
    "        'isoweekday', \n",
    "        'in_commercial',\n",
    "        'height_gte20',\n",
    "        'hair_color',\n",
    "        'hair_length',\n",
    "        'clothing',\n",
    "        'pred_gender',\n",
    "        'true_gender',\n",
    "        'is_host',\n",
    "        'screentime_seconds', \n",
    "        'variance_seconds_sq'\n",
    "    ]))\n",
    "    f.write('\\r\\n')\n",
    "    \n",
    "    def write_row(k, v):\n",
    "        name, video_id, channel_id, cshow_id, in_comm, bbox_height, color_id, length_id, clothing_id, gender_id = k\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        week_day = get_isoweekday(date)\n",
    "        row = [\n",
    "            name,\n",
    "            str(video_id),\n",
    "#             video_path,\n",
    "            channel_id_to_name[channel_id], \n",
    "            cshow_id_to_name[cshow_id],\n",
    "            date, \n",
    "            str(hour),\n",
    "            str(week_day),\n",
    "            str(in_comm),\n",
    "            str(bbox_height),\n",
    "            color_id_to_name.get(color_id, ''),\n",
    "            length_id_to_name.get(length_id, ''),\n",
    "            clothing_id_to_name.get(clothing_id, ''),\n",
    "            gender_id_to_name.get(gender_id, ''),\n",
    "            name_to_true_gender.get(name, ''),\n",
    "            str(get_identity_is_host(channel_id, name)),\n",
    "            str(v[0]),\n",
    "            str(v[1])\n",
    "        ]\n",
    "        f.write(','.join(row))\n",
    "        f.write('\\r\\n')\n",
    "    \n",
    "    def sort_fn(k):\n",
    "        name, video_id, channel_id, cshow_id, in_comm, bbox_height, color_id, length_id, clothing_id, gender_id = k\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        return name, date\n",
    "    \n",
    "    row_count = 0\n",
    "    for k in sorted(ident_st, key=sort_fn):\n",
    "        write_row(k, ident_st[k])\n",
    "        row_count += 1\n",
    "        if row_count % 10000 == 0:\n",
    "            print('  {} / {}'.format(row_count, len(ident_st)))\n",
    "    \n",
    "    print('Wrote {} rows'.format(row_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T19:36:40.979349Z",
     "start_time": "2019-01-10T19:36:40.928818Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Computing video id to commercials')\n",
    "VIDEO_ID_TO_COMMERCIALS = defaultdict(list)\n",
    "for c in get_commercials().select('video_id', 'min_frame', 'max_frame').collect():\n",
    "    VIDEO_ID_TO_COMMERCIALS[c.video_id].append(\n",
    "        (c.min_frame, c.max_frame)\n",
    "    )\n",
    "    \n",
    "def _annotate_frame_in_commercial(df):\n",
    "    assert ('video_id' in df.columns)\n",
    "    assert ('number' in df.columns)\n",
    "    def in_commercial_helper(video_id, frame_no):\n",
    "        if video_id in VIDEO_ID_TO_COMMERCIALS:\n",
    "            for c_min, c_max in VIDEO_ID_TO_COMMERCIALS[video_id]:\n",
    "                if frame_no >= c_min and frame_no <= c_max:\n",
    "                    return True\n",
    "        return False\n",
    "    my_udf = func.udf(in_commercial_helper, BooleanType())\n",
    "    df = df.withColumn(\n",
    "        'in_commercial', my_udf('video_id', 'number')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "print('Computing frames with host')\n",
    "if True:\n",
    "    frames_w_host_df = faces.where(\n",
    "        faces.host_probability > 0.5\n",
    "    ).select('frame_id').distinct()\n",
    "    spark.save('frames_w_host', frames_w_host_df)\n",
    "\n",
    "print('Computing frames to face count')\n",
    "if True:\n",
    "    frames_face_count_df = faces.groupBy(\n",
    "        'frame_id'\n",
    "    ).agg(\n",
    "        func.count(func.lit(1)).alias('face_count')\n",
    "    )\n",
    "    spark.save('frames_face_count', frames_face_count_df)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:35:46.514928Z",
     "start_time": "2019-01-10T01:35:33.541622Z"
    }
   },
   "outputs": [],
   "source": [
    "videos = get_videos()\n",
    "videos = videos.where((videos.duplicate == False) & (videos.corrupted == False))\n",
    "frames = get_frames()\n",
    "frames_with_host = spark.load('frames_w_host').withColumn('has_host', func.lit(True))\n",
    "frames_face_count = spark.load('frames_face_count')\n",
    "frames = frames.join(\n",
    "    videos, frames.video_id == videos.id\n",
    ").join(\n",
    "    frames_with_host, frames.id == frames_with_host.frame_id, 'left_outer'\n",
    ").join(\n",
    "    frames_face_count, frames.id == frames_face_count.frame_id, 'left_outer'\n",
    ").select(\n",
    "    'frames.*',\n",
    "    videos.channel_id,\n",
    "    videos.canonical_show_id,\n",
    "    frames_with_host.has_host,\n",
    "    frames_face_count.face_count\n",
    ").where(\n",
    "    ((videos.threeyears_dataset == True) & (frames.number % func.floor(videos.fps * 3) == 0)) | \\\n",
    "    ((videos.threeyears_dataset == False) & (frames.number % func.ceil(videos.fps * 3) == 0))\n",
    ")\n",
    "frames = _annotate_frame_in_commercial(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T01:40:54.035165Z",
     "start_time": "2019-01-10T01:35:46.516836Z"
    }
   },
   "outputs": [],
   "source": [
    "video_outfile = '/app/data/video_10y.csv'\n",
    "\n",
    "print('Summing over frames')\n",
    "with open(video_outfile, 'w') as f:\n",
    "    f.write(','.join([\n",
    "        'video_id',\n",
    "#         'video_path',\n",
    "        'channel', \n",
    "        'canonical_show', \n",
    "        'date', \n",
    "        'hour',\n",
    "        'isoweekday', \n",
    "        'in_commercial', \n",
    "        'host_onscreen',\n",
    "        'num_faces_onscreen',\n",
    "        'screentime_seconds'\n",
    "    ]))\n",
    "    f.write('\\r\\n')\n",
    "    \n",
    "    row_count = 0\n",
    "    for row in frames.groupBy(\n",
    "        'video_id', 'channel_id', 'canonical_show_id', 'in_commercial', 'has_host', 'face_count'\n",
    "    ).agg(\n",
    "        func.count(func.lit(1)).alias('frame_count')\n",
    "    ).sort(\n",
    "        'channel_id', 'canonical_show_id', 'video_id', 'in_commercial', 'has_host', 'face_count'\n",
    "    ).collect():\n",
    "        video_id = row.video_id\n",
    "        channel_id = row.channel_id\n",
    "        cshow_id = row.canonical_show_id\n",
    "        in_comm = row.in_commercial\n",
    "        has_host = row.has_host == True\n",
    "        face_count = row.face_count\n",
    "        if face_count is None:\n",
    "            face_count = 0\n",
    "        video_path = video_id_to_path[video_id]\n",
    "        date, hour = get_date_hour_from_path(video_path)\n",
    "        week_day = get_isoweekday(date)\n",
    "        f.write(','.join([\n",
    "            str(video_id),\n",
    "#             video_path,\n",
    "            channel_id_to_name[channel_id], \n",
    "            cshow_id_to_name[cshow_id],\n",
    "            date, \n",
    "            str(hour),\n",
    "            str(week_day),\n",
    "            str(in_comm), \n",
    "            str(has_host),\n",
    "            str(face_count),\n",
    "            str(row.frame_count * 3)\n",
    "        ]))\n",
    "        f.write('\\r\\n')\n",
    "        row_count += 1\n",
    "        if row_count % 10000 == 0:\n",
    "            print(row_count)\n",
    "    print('Wrote {} rows'.format(row_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T04:24:24.039813Z",
     "start_time": "2019-01-05T04:24:23.914518Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
