{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T22:07:54.235474Z",
     "start_time": "2019-07-22T22:07:53.415140Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from esper.widget import *\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "from esper.table_tennis.utils import *\n",
    "from esper.table_tennis.video_annotation import *\n",
    "from esper.table_tennis.pose_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T22:08:09.278039Z",
     "start_time": "2019-07-22T22:08:09.229358Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video = Video.objects.filter(path__contains='men_single_quarter_final_2')[0]\n",
    "video_id = video.id\n",
    "video_ids = [video_id]\n",
    "video.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find frames with people (Pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T14:25:21.918210Z",
     "start_time": "2019-03-11T14:25:21.198456Z"
    }
   },
   "outputs": [],
   "source": [
    "LABELED_TAG, _ = Tag.objects.get_or_create(name='openpose:labeled')\n",
    "frames_with_pose = Frame.objects.filter(video_id=video_id, tags=LABELED_TAG)\n",
    "num_frame_with_pose = len(frames_with_pose)\n",
    "print(\"{} frames contain poses out of {} frames ({:.02f}%)\".format(num_frame_with_pose, video.num_frames,\n",
    "                                                             100. * num_frame_with_pose/video.num_frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify sport field Scene\n",
    "Find long 2 people intervals, build classifier using RGB histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find frames with only two people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T05:16:10.880277Z",
     "start_time": "2019-05-21T05:16:04.965656Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "two_people_intrvlcol_short, two_people_intrvlcol_long = get_two_people_intrvlcol(video_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create montage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T19:50:39.703158Z",
     "start_time": "2019-03-06T19:50:32.117080Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "https://olimar.stanford.edu/hdd/table_tennis/match_intervals = intrvlcol2list(match_intrvlcol.get_intervallist(video_id))\n",
    "create_montage_from_intervals(match_intervals, out_path='/app/result/match_montage.jpg',\n",
    "                  width=2160, num_cols=10,\n",
    "                  )\n",
    "\n",
    "create_video_supercut(match_intervals, '/app/result/match_supercut.mp4')\n",
    "\n",
    "create_video_montage(match_intervals, '/app/result/match_montage.mp4', \n",
    "                     width=2160, num_cols=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify match scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T00:33:26.104316Z",
     "start_time": "2019-05-21T00:33:26.027803Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/app/data/histogram/{:07d}.bin'.format(video_id), 'rb') as f:\n",
    "    feature_all = np.frombuffer(f.read(), dtype=np.int).reshape((-1, 3*16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T00:33:29.190574Z",
     "start_time": "2019-05-21T00:33:29.162586Z"
    }
   },
   "outputs": [],
   "source": [
    "two_people_intervals_long = intrvlcol2list(two_people_intrvlcol_long, with_duration=True, sort_by_duration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T00:33:36.264209Z",
     "start_time": "2019-05-21T00:33:36.207671Z"
    }
   },
   "outputs": [],
   "source": [
    "# not work \n",
    "from esper.supercut import manual_select_candidates\n",
    "manual_select_candidates(interval2result(two_people_intervals_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T08:33:13.981444Z",
     "start_time": "2019-04-29T08:33:13.965772Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_SAMPLE_TRAIN = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T08:33:15.116469Z",
     "start_time": "2019-04-29T08:33:15.093312Z"
    }
   },
   "outputs": [],
   "source": [
    "# positive samples\n",
    "selected = [0, 2, 3, 7, 6, 5, 4, 8, 9, 10, 11, 15, 14, 13, 12, 16, 17, 18, 19, 23, 22, 21, 20, 24, 25, 26, 27, 31, 29, 32, 33, 34, 35, 39, 38, 36, 40, 41, 43, 47, 45, 49, 48]\n",
    "positive_intervals = [match_intervals[id] for id in selected]\n",
    "num_sample = 0\n",
    "POSITIVE_STRIDE = 5\n",
    "# positive_fids_all = [fid for (vid, sfid, efid, duration) in positive_intervals \n",
    "#                  for fid in range(sfid+5, efid-5, POSITIVE_STRIDE)]\n",
    "positive_fids_all = [fid for (vid, sfid, efid, duration) in positive_intervals \n",
    "                 for fid in range(sfid, efid)]\n",
    "print(\"Total positive samples \", len(positive_fids_all))\n",
    "random.shuffle(positive_fids_all)\n",
    "positive_fids = positive_fids_all[: NUM_SAMPLE_TRAIN]\n",
    "positive_feature = [feature_all[fid] for fid in positive_fids]\n",
    "positive_label = [1] * NUM_SAMPLE_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T05:46:25.105318Z",
     "start_time": "2019-03-11T05:46:25.048574Z"
    }
   },
   "outputs": [],
   "source": [
    "# obsolete\n",
    "positive_frames = VideoIntervalCollection({video_id: IntervalList([(fid, fid, 0) for fid in positive_fids])})\n",
    "esper_widget(intrvlcol2result(positive_frames, flat=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T14:42:38.547470Z",
     "start_time": "2019-03-11T14:41:47.644394Z"
    }
   },
   "outputs": [],
   "source": [
    "create_montage_from_intervals([(video_id, fid, fid) for fid in positive_fids], out_path='/app/result/positive_montage.jpg',\n",
    "                  width=2160, num_cols=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T08:34:24.177996Z",
     "start_time": "2019-04-29T08:33:55.805815Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# negative samples\n",
    "# NEGATIVE_STRIDE = 20\n",
    "# video_intrvlcol = VideoIntervalCollection({video_id : IntervalList([(0, video.num_frames-1, 0)])})\n",
    "# non_match_intrvlcol = video_intrvlcol.minus(two_people_intrvlcol_all)\n",
    "# negative_intervals = intrvlcol2list(non_match_intrvlcol)\n",
    "# negative_fids_all = [fid for (vid, sfid, efid, duration) in negative_intervals \n",
    "#                     for fid in range(sfid+5, efid-5, NEGATIVE_STRIDE)]\n",
    "positive_fids_large = [fid for interval in two_people_intrvlcol_all.get_intervallist(video_id).get_intervals() \n",
    "                          for fid in range(interval.start, interval.end+1)]\n",
    "negative_fids_all = [fid for fid in range(0, video.num_frames)\n",
    "                    if fid not in positive_fids_large]\n",
    "print(\"Total negative samples \", len(negative_fids_all))\n",
    "random.shuffle(negative_fids_all)\n",
    "negative_fids = negative_fids_all[: NUM_SAMPLE_TRAIN]\n",
    "negative_feature = [feature_all[fid] for fid in negative_fids]\n",
    "negative_label = [0] * NUM_SAMPLE_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T15:07:36.450820Z",
     "start_time": "2019-03-11T15:07:36.396260Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obsolete\n",
    "negative_frames = VideoIntervalCollection({video_id: IntervalList([(fid, fid, 0) for fid in negative_fids])})\n",
    "esper_widget(intrvlcol2result(negative_frames, flat=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T14:57:47.696964Z",
     "start_time": "2019-03-11T14:57:45.833392Z"
    }
   },
   "outputs": [],
   "source": [
    "negative_frames = Pose.objects.filter(frame__video_id=video_id, frame__number__in=negative_fids)\n",
    "len(negative_frames)\n",
    "# obsolete\n",
    "esper_widget(qs_to_result(negative_frames, stride=1, limit=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T14:40:07.436338Z",
     "start_time": "2019-03-11T14:39:13.136680Z"
    }
   },
   "outputs": [],
   "source": [
    "create_montage_from_intervals([(video_id, fid, fid) for fid in negative_fids], out_path='/app/result/negative_montage.jpg',\n",
    "                  width=2160, num_cols=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T08:34:29.708827Z",
     "start_time": "2019-04-29T08:34:29.670651Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=100)\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(positive_feature + negative_feature, positive_label + negative_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T08:34:42.562780Z",
     "start_time": "2019-04-29T08:34:36.151246Z"
    }
   },
   "outputs": [],
   "source": [
    "#Predict Output\n",
    "predicted_label = model.predict(feature_all) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T08:36:22.293886Z",
     "start_time": "2019-04-29T08:36:22.071208Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(list(predicted_label), open('/app/data/pkl/match_scene_cls.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment sport field scene into clip \n",
    "Here are two different algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter on two people intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T14:44:38.089852Z",
     "start_time": "2019-03-11T14:44:38.061297Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MATCH_THRESH = 0.9\n",
    "def filter_by_histogram(interval):\n",
    "    sfid, efid = interval.start, interval.end\n",
    "    predicted_interval = [predicted_label[fid] for fid in range(sfid, efid)]\n",
    "    return 1. * np.sum(predicted_interval) / (efid - sfid) > MATCH_THRESH\n",
    "match_scene_intrvlcol = two_people_intrvlcol.filter(filter_by_histogram)\n",
    "count_intervals(match_scene_intrvlcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T05:55:32.235301Z",
     "start_time": "2019-03-11T05:55:32.212513Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obsolete\n",
    "esper_widget(intrvlcol2result(match_scene_intrvlcol, flat=True), use_jupyter_keybindings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T15:10:14.869512Z",
     "start_time": "2019-03-11T15:10:09.359253Z"
    }
   },
   "outputs": [],
   "source": [
    "create_montage_from_intervals(intrvlcol2list(match_scene_intrvlcol, with_duration=False), out_path='/app/result/match_scene_montage.jpg',\n",
    "                  width=2160, num_cols=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T06:27:03.272053Z",
     "start_time": "2019-03-11T06:27:03.257852Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(match_scene_intrvlcol, open('/app/result/match_scene_intrvlcol.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge from classified match scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:44:28.320375Z",
     "start_time": "2019-05-21T16:44:28.284534Z"
    }
   },
   "outputs": [],
   "source": [
    "match_scene_cls = pickle.load(open('/app/data/pkl/match_scene_cls.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T17:12:50.807853Z",
     "start_time": "2019-05-21T17:12:49.779546Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intervals = [Interval(Bounds3D(fid, fid+1)) for fid, cls in enumerate(match_scene_cls) if cls]\n",
    "match_scene_is = IntervalSet(intervals).dilate(5).coalesce(('t1', 't2'), Bounds3D.span).dilate(-5).filter_size(min_size=25)\n",
    "match_scene_is.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:53:58.403443Z",
     "start_time": "2019-05-21T16:53:58.372708Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx, intervalSet in enumerate(match_scene_is.get_intervals()):\n",
    "    print(idx, intervalSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:44:34.405244Z",
     "start_time": "2019-05-21T16:44:34.393626Z"
    }
   },
   "outputs": [],
   "source": [
    "match_scene_ism = IntervalSetMapping({video_id: match_scene_is})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:44:38.575840Z",
     "start_time": "2019-05-21T16:44:38.557618Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_duration(match_scene_ism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:46:24.022042Z",
     "start_time": "2019-05-21T16:46:18.071929Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IntervalSetMapping_to_vgrid(IntervalSetMapping_frame_to_second(match_scene_ism), flat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Hit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect sound peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T18:18:43.757359Z",
     "start_time": "2019-07-08T18:18:43.731695Z"
    }
   },
   "outputs": [],
   "source": [
    "hit_dict_split = pickle.load(open('/app/data/pkl/hit_annotation.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T18:19:47.609972Z",
     "start_time": "2019-07-08T18:19:47.556193Z"
    }
   },
   "outputs": [],
   "source": [
    "point = hit_dict_split['Tabletennis_2012_Olympics_men_single_final_gold']['HW'][4]\n",
    "sfid, efid = point[0]['fid'], point[-1]['fid']\n",
    "sfid -= 25\n",
    "efid += 25\n",
    "hit_time = [(hit['fid'] - sfid) / video.fps for hit in point]\n",
    "hit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T18:19:51.399344Z",
     "start_time": "2019-07-08T18:19:49.798562Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_path = '/app/tmp/test_audio.wav'\n",
    "video_path = '/app/tmp/test_video.mp4'\n",
    "video.extract_audio(segment=(1.*sfid/video.fps, 1.*efid/video.fps), output_path=audio_path)\n",
    "video.download(segment=(1.*sfid/video.fps, 1.*efid/video.fps), output_path=video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T18:19:53.705525Z",
     "start_time": "2019-07-08T18:19:53.444208Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# analyze sound\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "fs, audio_signal = wavfile.read(audio_path)\n",
    "audio_signal = audio_signal.max(axis=1)\n",
    "audio_signal_filter = butter_highpass_filter(audio_signal, 1000, fs)\n",
    "\n",
    "# from peakdetect import peakdetect\n",
    "# peaks = peakdetect(audio_signal, lookahead=100)\n",
    "\n",
    "# from scipy.signal import find_peaks_cwt\n",
    "# indexes = find_peaks_cwt(audio_signal, np.arange(len(audio_signal)))\n",
    "\n",
    "peaks, _ = find_peaks(audio_signal_filter, prominence=1, distance=fs/20, height=500)\n",
    "\n",
    "audio_time = np.linspace(0, len(audio_signal)/fs, num=len(audio_signal))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(audio_time, audio_signal_filter)\n",
    "plt.scatter(hit_time, [2000] * len(hit_time), c='r', linewidths=2)\n",
    "\n",
    "plt.plot(peaks / fs, audio_signal_filter[peaks], 'gx', markersize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T19:57:45.749584Z",
     "start_time": "2019-06-03T19:57:45.709868Z"
    },
    "scrolled": true
   },
   "source": [
    "peak_fid = [int(np.round(1. * p / fs * video.fps + sfid)) for p in peaks]\n",
    "peak_fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T19:39:01.267709Z",
     "start_time": "2019-06-03T19:39:01.092295Z"
    }
   },
   "outputs": [],
   "source": [
    "window_size = 200\n",
    "\n",
    "def get_frequency_spectrum(y, fs): \n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n / fs\n",
    "    frq = k / T # two sides frequency range\n",
    "    frq = frq[range(n//2)] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n//2)]\n",
    "    return frq, abs(Y)\n",
    "\n",
    "plt.figure()\n",
    "for i in range(10):\n",
    "    frq, Y = get_frequency_spectrum(audio_signal[peaks[i] - window_size: peaks[i] + window_size], fs)\n",
    "    plt.plot(frq, Y, label=str(i))\n",
    "plt.xlim([0, 10000])\n",
    "plt.ylim([0, 600])\n",
    "plt.legend()\n",
    "    \n",
    "# frq, Y = get_frequency_spectrum(audio_signal[peaks[8] - window_size: peaks[8] + window_size], fs)\n",
    "# plt.plot(frq, Y,'r') \n",
    "# frq, Y = get_frequency_spectrum(audio_signal[peaks[9] - window_size: peaks[9] + window_size], fs)\n",
    "# plt.plot(frq, Y,'b') \n",
    "# frq, Y = get_frequency_spectrum(audio_signal[peaks[10] - window_size: peaks[10] + window_size], fs)\n",
    "# plt.plot(frq, Y,'g') \n",
    "# frq, Y = get_frequency_spectrum(audio_signal[peaks[13] - window_size: peaks[13] + window_size], fs)\n",
    "# plt.plot(frq, Y,'y') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect foot motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T06:12:10.354042Z",
     "start_time": "2019-04-16T06:12:10.339569Z"
    }
   },
   "outputs": [],
   "source": [
    "match_scene_intrvlcol = pickle.load(open('/app/result/match_scene_intrvlcol.pkl', 'rb'))\n",
    "match_scene_intervals = intrvlcol2list(match_scene_intrvlcol, sort_by_duration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T15:26:52.104338Z",
     "start_time": "2019-03-11T15:26:52.080319Z"
    }
   },
   "outputs": [],
   "source": [
    "esper_widget(interval2result(match_scene_intervals[9:10]), disable_caption=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T06:12:20.062690Z",
     "start_time": "2019-04-16T06:12:20.044697Z"
    }
   },
   "outputs": [],
   "source": [
    "sfid, efid = match_scene_intervals[9][1:3]\n",
    "# video.download(segment=(sfid/video.fps, efid/video.fps), output_path='/app/tmp/point.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T15:47:34.975816Z",
     "start_time": "2019-03-11T15:47:34.954313Z"
    }
   },
   "outputs": [],
   "source": [
    "joints_to_plot = [Pose.Neck, Pose.LShoulder, Pose.LElbow, Pose.LWrist, Pose.LHip, Pose.LKnee, Pose.LAnkle]\n",
    "joints_to_plot_name = ['Neck', 'LShoulder', 'LElbow', 'LWrist', 'LHip', 'LKnee', 'LAnkle']\n",
    "def get_trajectory(fid2pose):\n",
    "    trajectory_X = {joint: [] for joint in joints_to_plot}\n",
    "    trajectory_Y = {joint: [] for joint in joints_to_plot}\n",
    "    xtick_X = {joint: [] for joint in joints_to_plot}\n",
    "    xtick_Y = {joint: [] for joint in joints_to_plot}\n",
    "    for fid in sorted(fid2pose):\n",
    "        keypoints = fid2pose[fid]._format_keypoints()\n",
    "        for joint in joints_to_plot:\n",
    "            X = keypoints[joint][0]\n",
    "            if 0 < X and X < 1: \n",
    "                trajectory_X[joint].append(X)\n",
    "                xtick_X[joint].append(fid)\n",
    "            Y = keypoints[joint][1]\n",
    "            if 0 < Y and Y < 1:\n",
    "                trajectory_Y[joint].append(Y)\n",
    "                xtick_Y[joint].append(fid)\n",
    "    return xtick_X, xtick_Y, trajectory_X, trajectory_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T15:47:36.295631Z",
     "start_time": "2019-03-11T15:47:35.837871Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "xtick_X, xtick_Y, trajectory_X, trajectory_Y = get_trajectory(foreground_pose)\n",
    "for id, joint in enumerate(joints_to_plot):\n",
    "    plt.plot(xtick_X[joint], trajectory_X[joint], label=joints_to_plot_name[id] + 'X')\n",
    "    plt.plot(xtick_Y[joint], trajectory_Y[joint], '--', label=joints_to_plot_name[id] + 'Y')\n",
    "legend = plt.legend(loc='lower right')\n",
    "plt.figure()\n",
    "xtick_X, xtick_Y, trajectory_X, trajectory_Y = get_trajectory(background_pose)\n",
    "for id, joint in enumerate(joints_to_plot):\n",
    "    plt.plot(xtick_X[joint], trajectory_X[joint], label=joints_to_plot_name[id] + 'X')\n",
    "    plt.plot(xtick_Y[joint], trajectory_Y[joint], '--', label=joints_to_plot_name[id] + 'Y')\n",
    "legend = plt.legend(loc='lower right')foreground_pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate foreground/background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T07:46:58.112910Z",
     "start_time": "2019-04-28T07:46:58.058835Z"
    }
   },
   "outputs": [],
   "source": [
    "from esper.table_tennis.parse_match import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T07:46:58.882200Z",
     "start_time": "2019-04-28T07:46:58.820734Z"
    }
   },
   "outputs": [],
   "source": [
    "match_scene_intrvlcol = pickle.load(open('/app/result/match_scene_intrvlcol.pkl', 'rb'))\n",
    "match_scene_intervals = intrvlcol2list(match_scene_intrvlcol, sort_by_duration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T06:41:19.921545Z",
     "start_time": "2019-04-16T06:41:19.644628Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "foreground_pose, background_pose = group_pose_from_interval(match_scene_intervals[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T06:41:55.888988Z",
     "start_time": "2019-04-16T06:41:20.677883Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_foreground_train = collect_histogram(foreground_pose)\n",
    "hist_background_train = collect_histogram(background_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T06:41:59.166636Z",
     "start_time": "2019-04-16T06:41:59.149451Z"
    }
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=100)\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(hist_foreground_train + hist_background_train, \n",
    "          [1]*len(hist_foreground_train) + [0]*len(hist_background_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T06:55:56.646212Z",
     "start_time": "2019-04-16T06:52:20.950767Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "match_scene_intrvlcol = pickle.load(open('/app/result/match_scene_intrvlcol.pkl', 'rb'))\n",
    "match_scene_intervals_foreground = []\n",
    "match_scene_intervals_background = []\n",
    "num_sample = 50\n",
    "\n",
    "for interval in match_scene_intervals:\n",
    "    foreground_pose, background_pose = group_pose_from_interval(interval)\n",
    "    if len(foreground_pose) < num_sample:\n",
    "        continue\n",
    "    pose_list_sample = random.sample(foreground_pose, num_sample)\n",
    "    hist_foreground_test = collect_histogram(pose_list_sample)\n",
    "    \n",
    "    predicted_label = model.predict(hist_foreground_test)\n",
    "    if 1. * np.sum(predicted_label) / len(predicted_label) > 0.5:\n",
    "        match_scene_intervals_foreground.append(interval)\n",
    "    else:\n",
    "        match_scene_intervals_background.append(interval)\n",
    "    print(\"Foreground\", 1. * np.sum(predicted_label) / len(predicted_label))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T07:28:12.531716Z",
     "start_time": "2019-04-16T07:28:12.493406Z"
    }
   },
   "outputs": [],
   "source": [
    "match_scene_intervals_dict = {'HW_foreground': match_scene_intervals_foreground,\n",
    "                              'JZ_foreground': match_scene_intervals_background}\n",
    "pickle.dump(match_scene_intervals_dict, open('/app/result/match_scene_intervals_dict.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T07:33:25.057789Z",
     "start_time": "2019-04-16T07:33:22.239931Z"
    }
   },
   "outputs": [],
   "source": [
    "create_montage(match_scene_intervals_foreground, out_path='/app/result/foreground_montage.jpg',\n",
    "                  width=2160, num_cols=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T07:33:28.102011Z",
     "start_time": "2019-04-16T07:33:26.623697Z"
    }
   },
   "outputs": [],
   "source": [
    "create_montage(match_scene_intervals_background, out_path='/app/result/background_montage.jpg',\n",
    "                  width=2160, num_cols=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1231px",
    "left": "0px",
    "right": "1782.4px",
    "top": "110px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
